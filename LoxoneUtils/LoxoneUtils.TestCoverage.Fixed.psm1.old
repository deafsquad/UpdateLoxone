#Requires -Version 5.0
<#
.SYNOPSIS
    Test coverage analysis module for UpdateLoxone

.DESCRIPTION
    Provides comprehensive test coverage analysis functionality including:
    - Function discovery across all modules
    - Test coverage calculation
    - Report generation with summary and details
    - Deprecated test reference tracking
    - Function usage analysis
#>

# Module variables
$script:ModulePath = if ($PSScriptRoot) { 
    Split-Path $PSScriptRoot -Parent 
} else { 
    # Fallback when PSScriptRoot is not available (e.g., in certain admin contexts)
    $moduleFile = (Get-Module LoxoneUtils).Path
    if ($moduleFile) {
        Split-Path (Split-Path $moduleFile -Parent) -Parent
    } else {
        # Ultimate fallback - use current location
        Get-Location
    }
}
$script:TestPath = Join-Path $script:ModulePath 'tests'


function ConvertFrom-JsonToHashtable {
    param([string]$Json)
    
    $obj = $Json | ConvertFrom-Json
    $result = @{
        grandfathered = @{}
        permanent = @{}
    }
    
    if ($obj.grandfathered) {
        $obj.grandfathered.PSObject.Properties | ForEach-Object {
            $result.grandfathered[$_.Name] = $_.Value
        }
    }
    
    if ($obj.permanent) {
        $obj.permanent.PSObject.Properties | ForEach-Object {
            $result.permanent[$_.Name] = $_.Value
        }
    }
    
    # Add metadata if present
    if ($obj.metadata) {
        $result.metadata = $obj.metadata
    }
    
    return $result
}


function Get-FunctionDocumentation {
    param(
        [string]$FunctionName,
        [string]$FileContent
    )
    
    $docInfo = @{
        Synopsis = ""
        Description = ""
        Parameters = @{}
        Examples = @()
        HasDocumentation = $false
        CompletionScore = 0
    }
    
    # Find the function definition and extract comment-based help
    $pattern = "(?ms)((?:<#[\s\S]*?#>)|(?:(?:^|\n)\s*#.*\n)+)\s*function\s+$FunctionName\s*{"
    
    if ($FileContent -match $pattern) {
        $helpBlock = $matches[1]
        $docInfo.HasDocumentation = $true
        
        # Extract SYNOPSIS
        if ($helpBlock -match '\.SYNOPSIS\s*\n\s*(.+?)(?=\n\s*\.|#>|$)') {
            $docInfo.Synopsis = $matches[1].Trim()
            $docInfo.CompletionScore += 25
        }
        
        # Extract DESCRIPTION
        if ($helpBlock -match '\.DESCRIPTION\s*\n([\s\S]+?)(?=\n\s*\.|#>|$)') {
            $desc = $matches[1] -split '\n' | ForEach-Object { $_.Trim() } | Where-Object { $_ }
            $docInfo.Description = $desc -join ' '
            $docInfo.CompletionScore += 25
        }
        
        # Extract PARAMETER info
        $paramMatches = [regex]::Matches($helpBlock, '\.PARAMETER\s+(\w+)\s*\n\s*(.+?)(?=\n\s*\.|#>|$)')
        foreach ($match in $paramMatches) {
            $paramName = $match.Groups[1].Value
            $paramDesc = $match.Groups[2].Value.Trim()
            $docInfo.Parameters[$paramName] = $paramDesc
        }
        if ($docInfo.Parameters.Count -gt 0) {
            $docInfo.CompletionScore += 25
        }
        
        # Extract EXAMPLE info
        $exampleMatches = [regex]::Matches($helpBlock, '\.EXAMPLE\s*\n([\s\S]+?)(?=\n\s*\.|#>|$)')
        foreach ($match in $exampleMatches) {
            $docInfo.Examples += $match.Groups[1].Value.Trim()
        }
        if ($docInfo.Examples.Count -gt 0) {
            $docInfo.CompletionScore += 25
        }
    }
    
    return $docInfo
}


function Get-TestCoverage {
    <#
    .SYNOPSIS
        Analyzes test coverage for the UpdateLoxone project
    
    .DESCRIPTION
        Performs comprehensive analysis of test coverage including function discovery,
        test mapping, and coverage calculation for both exported and internal functions
    
    .PARAMETER ShowDetails
        Shows detailed coverage information in console output
    
    .PARAMETER GenerateReport
        Generates a detailed coverage report file
    
    .PARAMETER OutputPath
        Path where the coverage report will be saved. If not specified, uses TestResults/coverage.md
    
    .PARAMETER CheckUsage
        Performs additional analysis to check if functions are used in the codebase
    
    .PARAMETER ShowIndex
        Shows an index/table of contents in the console output
    
    .PARAMETER IncludeTestResults
        Include test execution results (pass/fail/skip) from the most recent test run
    
    .PARAMETER TestResultsPath
        Path to test results directory. If not specified, uses most recent TestRun
    
    .EXAMPLE
        Get-TestCoverage -GenerateReport -ShowDetails
        
    .EXAMPLE
        Get-TestCoverage -CheckUsage -OutputPath "C:\Reports\coverage.md"
    #>
    [CmdletBinding()]
    param(
        [switch]$ShowDetails,
        [switch]$GenerateReport,
        [string]$OutputPath,
        [switch]$CheckUsage,
        [switch]$ShowIndex,
        [switch]$IncludeTestResults,
        [string]$TestResultsPath
    )
    
    # Set default output path
    if (-not $OutputPath -and $GenerateReport) {
        $OutputPath = Join-Path $script:TestPath "TestResults/coverage.md"
    }
    
    # Initialize collections
    $allFunctions = @{}
    $functionsByModule = @{}
    $deprecatedTestReferences = @{}
    $testFilesAnalyzed = 0
    $totalTestReferences = 0
    
    Write-Host "Enhanced Test Coverage Analysis for UpdateLoxone" -ForegroundColor Cyan
    Write-Host "===============================================" -ForegroundColor Cyan
    Write-Host "Analysis started: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')" -ForegroundColor Gray
    Write-Host ""
    
    # Phase 1: Extract all functions from source
    Write-Host "Phase 1: Scanning module files..." -ForegroundColor Yellow
    $modulePath = Join-Path $script:ModulePath 'LoxoneUtils'
    $moduleFiles = Get-ChildItem -Path $modulePath -Filter "*.psm1" -File
    
    foreach ($moduleFile in $moduleFiles) {
        Write-Host "  â€¢ $($moduleFile.Name)" -ForegroundColor Gray
        $content = Get-Content $moduleFile.FullName -Raw
        
        # Find all function definitions
        $functionMatches = [regex]::Matches($content, 'function\s+(?<name>[\w-]+)\s*{')
        
        $moduleFunctions = @()
        foreach ($match in $functionMatches) {
            $funcName = $match.Groups['name'].Value
            $moduleFunctions += $funcName
            # Extract documentation for the function
            $docInfo = Get-FunctionDocumentation -FunctionName $funcName -FileContent $content
            
            $allFunctions[$funcName] = @{
                Module = $moduleFile.BaseName
                File = $moduleFile.Name
                Exported = $false
                Tested = $false
                TestCount = 0
                TestDetails = @{}
                UsedInCodebase = $false
                UsageLocations = @()
                IsInternal = $false
                Documentation = $docInfo
            }
        }
        
        $functionsByModule[$moduleFile.BaseName] = $moduleFunctions
    }
    
    # Phase 2: Check which functions are exported
    Write-Host ""
    Write-Host "Phase 2: Analyzing module manifest..." -ForegroundColor Yellow
    $psdPath = Join-Path $modulePath 'LoxoneUtils.psd1'
    if (Test-Path $psdPath) {
        $psdContent = Get-Content $psdPath -Raw
        
        # Extract FunctionsToExport
        if ($psdContent -match "FunctionsToExport\s*=\s*@\(([^)]+)\)") {
            $exportedFuncs = $matches[1] -split "[\s,']+" | Where-Object { 
                $_ -and $_ -ne '@(' -and $_ -ne ')' -and $_ -notmatch '^\s*#' 
            }
            
            $validExports = 0
            $invalidExports = 0
            
            foreach ($func in $exportedFuncs) {
                if ($allFunctions.ContainsKey($func)) {
                    $allFunctions[$func].Exported = $true
                    $validExports++
                } else {
                    $invalidExports++
                }
            }
            
            Write-Host "  â€¢ Valid exports: $validExports" -ForegroundColor Green
            if ($invalidExports -gt 0) {
                Write-Host "  â€¢ Invalid exports: $invalidExports" -ForegroundColor Red
            }
        }
    }
    
    # Determine internal functions
    foreach ($func in $allFunctions.Keys) {
        if (-not $allFunctions[$func].Exported) {
            $allFunctions[$func].IsInternal = $true
        }
    }
    
    # Phase 3: Check function usage in codebase
    if ($CheckUsage) {
        Write-Host ""
        Write-Host "Phase 3: Checking function usage in codebase..." -ForegroundColor Yellow
        Write-Host "  Note: Fixed several usage detection issues:" -ForegroundColor Gray
        Write-Host "  - Added tests directory to search scope" -ForegroundColor Gray
        Write-Host "  - Improved intra-module usage detection" -ForegroundColor Gray
        Write-Host "  - Added special handling for TestCoverage functions" -ForegroundColor Gray
        
        # Get all PowerShell files in the entire project
        $projectRoot = Split-Path -Parent $script:ModulePath
        $allPSFiles = @()
        # Search in module directory
        $allPSFiles += Get-ChildItem -Path $script:ModulePath -Filter "*.ps1" -File -ErrorAction SilentlyContinue
        $allPSFiles += Get-ChildItem -Path $modulePath -Filter "*.psm1" -File -ErrorAction SilentlyContinue
        # Search in project root for main scripts
        $allPSFiles += Get-ChildItem -Path $projectRoot -Filter "*.ps1" -File -ErrorAction SilentlyContinue
        # Search in LoxoneUtils subdirectory for all modules
        $loxoneUtilsPath = Join-Path $projectRoot "LoxoneUtils"
        if (Test-Path $loxoneUtilsPath) {
            $allPSFiles += Get-ChildItem -Path $loxoneUtilsPath -Filter "*.psm1" -File -ErrorAction SilentlyContinue
        }
        # Search in tests directory for test runner scripts
        $testsPath = Join-Path $projectRoot "tests"
        if (Test-Path $testsPath) {
            $allPSFiles += Get-ChildItem -Path $testsPath -Filter "*.ps1" -File -ErrorAction SilentlyContinue
        }
        
        $filesScanned = 0
        foreach ($funcName in $allFunctions.Keys) {
            foreach ($psFile in $allPSFiles) {
                $fileContent = Get-Content $psFile.FullName -Raw
                
                # For functions defined in the same file, only check for usage outside function definition
                # This allows detection of intra-module usage (e.g., OnRemove handlers, internal calls)
                $isDefiningFile = ($psFile.BaseName -eq $allFunctions[$funcName].Module)
                if ($isDefiningFile) {
                    # Skip function definition itself, but check for usage in the same file
                    # Look for the function definition to exclude that line
                    $functionDefPattern = "function\s+$funcName\s*\{"
                    if ($fileContent -match $functionDefPattern) {
                        # Remove the function definition line and surrounding context
                        $defMatch = [regex]::Match($fileContent, $functionDefPattern)
                        $beforeDef = $fileContent.Substring(0, $defMatch.Index)
                        $afterDef = $fileContent.Substring($defMatch.Index + $defMatch.Length)
                        $fileContent = $beforeDef + $afterDef
                    }
                }
                
                # Look for function calls with improved regex patterns
                # Match: function name followed by space, parameter (-), pipe (|), newline, or in a command
                $patterns = @(
                    "\b$funcName\b\s*(-[\w]+|\s|$|\|)",  # Standard call with parameters or pipe
                    "\b$funcName\b[\r\n]",                 # Function followed by newline
                    "&\s*[`'`"]?$funcName[`'`"]?",          # Call operator & 'function' or & function
                    "\.$funcName\s*\(",                    # Method-style call
                    "\`[$funcName\`]",                       # Type accelerator style
                    "Export-ModuleMember.*\b$funcName\b",  # Export statements
                    "FunctionsToExport.*[`'`"]$funcName[`'`"]", # Module manifest exports
                    "\`$$funcName\b",                      # Assignment from function call
                    "=\s*$funcName\b"                      # Variable assignment
                )
                
                $found = $false
                foreach ($pattern in $patterns) {
                    if ($fileContent -match $pattern) {
                        # Additional validation: ensure it's not just the function definition
                        $match = [regex]::Match($fileContent, $pattern)
                        $context = ""
                        if ($match.Success) {
                            # Get some context around the match
                            $start = [Math]::Max(0, $match.Index - 20)
                            $length = [Math]::Min(40, $fileContent.Length - $start)
                            $context = $fileContent.Substring($start, $length)
                            
                            # Skip if this looks like a function definition
                            if ($context -notmatch "^\s*function\s+$funcName\s*\{") {
                                $found = $true
                                break
                            }
                        }
                    }
                }
                
                # Special handling for TestCoverage functions - they may be called from PowerShell sessions
                # Mark TestCoverage module functions as used since they're designed for external invocation
                if (-not $found -and $allFunctions[$funcName].Module -eq "LoxoneUtils.TestCoverage") {
                    if ($funcName -in @('Get-TestCoverage', 'New-TestCoverageReport', 'Get-TestResults')) {
                        $found = $true
                        $allFunctions[$funcName].UsageLocations += "External PowerShell sessions"
                    }
                }
                
                if ($found) {
                    $allFunctions[$funcName].UsedInCodebase = $true
                    $allFunctions[$funcName].UsageLocations += $psFile.Name
                }
                $filesScanned++
            }
        }
        Write-Host "  â€¢ Files scanned: $($allPSFiles.Count)" -ForegroundColor Gray
        Write-Host "  â€¢ Functions checked: $($allFunctions.Count)" -ForegroundColor Gray
    }
    
    # Phase 4: Scan test files
    Write-Host ""
    Write-Host "Phase 4: Scanning test files..." -ForegroundColor Yellow
    $testFiles = Get-ChildItem -Path $script:TestPath -Filter "*.Tests.ps1" -Recurse
    
    foreach ($testFile in $testFiles) {
        Write-Host "  â€¢ $($testFile.Name)" -ForegroundColor Gray
        $testContent = Get-Content $testFile.FullName -Raw
        $testFilesAnalyzed++
        
        # Check each function for test coverage
        foreach ($funcName in $allFunctions.Keys) {
            if ($testContent -match "\b$funcName\b") {
                $allFunctions[$funcName].Tested = $true
                $allFunctions[$funcName].TestCount++
                $totalTestReferences++
                
                # Get detailed test context
                $testContexts = Get-TestContext -TestContent $testContent -FunctionName $funcName -TestFileName $testFile.Name
                
                foreach ($context in $testContexts) {
                    $key = "$($context.Describe) - $($context.It)"
                    if (-not $allFunctions[$funcName].TestDetails.ContainsKey($key)) {
                        $allFunctions[$funcName].TestDetails[$key] = @{
                            Describe = $context.Describe
                            It = $context.It
                            TestFiles = @()
                            Expectations = $context.Expectations
                        }
                    }
                    $allFunctions[$funcName].TestDetails[$key].TestFiles += $context.TestFile
                }
            }
        }
        
        # Find deprecated test references (functions that don't exist)
        # Only look for specific patterns that indicate actual function calls
        $deprecatedFound = @{}
        
        # Pattern 1: Mock statements for functions that don't exist
        # This is the most reliable indicator of deprecated functions
        $mockPattern = 'Mock\s+(?:-CommandName\s+)?[`''"]?([A-Z][\w-]+)[`''"]?\s*(?:-|{|\s|$)'
        $mockMatches = [regex]::Matches($testContent, $mockPattern)
        foreach ($match in $mockMatches) {
            $funcName = $match.Groups[1].Value
            
            # Get context to check if this is a parameter name in Mock -ParameterFilter
            $contextStart = [Math]::Max(0, $match.Index - 50)
            $contextEnd = [Math]::Min($testContent.Length, $match.Index + 150)
            $context = $testContent.Substring($contextStart, $contextEnd - $contextStart)
            
            # Skip if this appears to be a parameter name in -ParameterFilter
            if ($context -match '-ParameterFilter\s*{\s*\$' + $funcName) {
                continue
            }
            
            # Skip if it's a known function
            if (-not $allFunctions.ContainsKey($funcName)) {
                # Skip PowerShell built-in cmdlets and known external modules
                $isBuiltIn = $false
                
                # Common PowerShell cmdlets
                if ($funcName -match '^(Get|Set|New|Remove|Add|Clear|Copy|Move|Rename|Test|Out|Write|Read|Import|Export|ConvertTo|ConvertFrom|Select|Where|Sort|Group|Format|Measure|Compare|Start|Stop|Restart|Wait|Invoke|Enter|Exit|Push|Pop|Join|Split|Resolve|Update|Register|Unregister|Enable|Disable|Install|Uninstall|Save|Restore|Backup|Compress|Expand|Publish|Unpublish|Grant|Revoke|Block|Unblock|Protect|Unprotect|Initialize|Reset|Submit|Approve|Deny|Send|Receive|Connect|Disconnect|Suspend|Resume|Debug|Trace|Show|Hide|Lock|Unlock|Limit|Skip|Use)-\w+') {
                    $isBuiltIn = $true
                }
                
                # BurntToast module functions
                elseif ($funcName -match '^(New-BT|Update-BT|Submit-BT|Get-BT|Remove-BT)\w+') {
                    $isBuiltIn = $true
                }
                elseif ($funcName -eq 'BurntToast' -or $funcName -eq 'New-BurntToastNotification') {
                    $isBuiltIn = $true
                }
                
                # Common .NET types and methods
                elseif ($funcName -in @('New-Object', 'Get-Member', 'Add-Type', 'Using')) {
                    $isBuiltIn = $true
                }
                
                # Parameter names that look like functions but aren't
                elseif ($funcName -match '^(Path|FilePath|LiteralPath|Name|Value|Property|Filter|Include|Exclude|Force|Recurse|WhatIf|Confirm|Verbose|Debug|ErrorAction|WarningAction|InformationAction|ErrorVariable|WarningVariable|InformationVariable|OutVariable|OutBuffer|PipelineVariable|PassThru|NoTypeInformation|AsJob|ThrottleLimit|TimeoutSec|MaxRetries|Interval|Delay|Wait|Timeout|Port|ComputerName|Credential|Session|UseSSL|SkipCertificateCheck|Headers|Method|Uri|Body|ContentType|UserAgent|TransferEncoding|DestinationPath|SourcePath|Destination|Source|Target|InputObject|OutputPath|Append|NoClobber|Width|Wrap|AutoSize|DisplayError|ShowError|View|GroupBy|Property|Status|Before|After|First|Last|Skip|SkipLast|Unique|AsHashTable|CaseSensitive|Culture|Ascending|Descending|Top|Bottom|StatusMessage|MSEntry|InitialVersion|MSIP|ExePath|CurrentWeight|MaxRetries|IsInteractive|ErrorOccurred|InstalledAppVersion|TargetVersion|InputAddress|InputString|AppData|ConfigData|UpdateXmlUrl|ZipPath|InputFile|InstallerPath|FilePath)$') {
                    $isBuiltIn = $true
                }
                
                # Specific functions from our codebase that were removed/renamed
                elseif ($funcName -in @('Get-LoxoneConfigToastAppId', 'Compare-LoxoneVersion', 'Get-CurrentVersion', 'Install-LoxoneConfig')) {
                    # These are legitimate deprecated functions - let them be flagged
                    $isBuiltIn = $false
                }
                
                # Common parameter names that shouldn't be flagged as functions
                elseif ($funcName -in @('ZipPath', 'AppName', 'ComponentName', 'InstallerPath', 'Url', 'InputFile', 'InputString', 'Thumbprint', 'DownloadDir', 'EnableCRC', 'CheckEnabled', 'CheckAppUpdate', 'AttemptedUpdate', 'ExpectedFilesize', 'StepNumber', 'TotalDownloads', 'PSTypeName')) {
                    $isBuiltIn = $true
                }
                
                if (-not $isBuiltIn) {
                    $deprecatedFound[$funcName] = $true
                }
            }
        }
        
        # Pattern 2: Function calls in test assertions (Should -Contain, etc.)
        # IMPORTANT: This pattern often catches property names, not function calls
        # Only include if it's checking for exported functions
        $assertionPattern = 'Should\s+-Contain\s+[`''"]([A-Z][\w-]+)[`''"]'
        $assertionMatches = [regex]::Matches($testContent, $assertionPattern)
        foreach ($match in $assertionMatches) {
            $funcName = $match.Groups[1].Value
            # Only flag if context suggests it's checking for functions
            $contextStart = [Math]::Max(0, $match.Index - 100)
            $contextLength = [Math]::Min(200, $testContent.Length - $contextStart)
            $context = $testContent.Substring($contextStart, $contextLength)
            
            # Skip if it's checking properties or parameters
            if ($context -match '\.Properties\.Name\s*\|\s*Should\s+-Contain' -or
                $context -match 'PSObject\.Properties' -or
                $context -match 'ParameterSets.*\.Parameters' -or
                $context -match '\$\w+\s*\|\s*Should\s+-Contain' -or
                $context -match '\.Parameters\.Keys\s*\|\s*Should\s+-Contain' -or
                $context -match '\.Parameters\s*\|\s*Should\s+-Contain' -or
                $context -match '\.Parameters\.' -or
                $context -match 'Get-Command\s+\S+\s+-Module') {
                continue
            }
            
            # Also skip if the function name is clearly a parameter name
            if ($funcName -in @('MSEntry', 'ExePath', 'InputAddress', 'InputString', 'AppName', 
                               'AppData', 'ConfigData', 'UpdateXmlUrl', 'ZipPath', 'InputFile', 
                               'InstallerPath', 'FilePath')) {
                continue
            }
            
            # Only flag if it's likely checking for exported functions
            if ($context -match 'Export.*Functions|\.Functions\.Keys' -and 
                $context -notmatch '\.Parameters') {
                if (-not $allFunctions.ContainsKey($funcName)) {
                    $deprecatedFound[$funcName] = $true
                }
            }
        }
        
        # Pattern 3: Get-Command checks for our functions  
        $getCommandPattern = 'Get-Command\s+[`''"]?([A-Z][\w-]+)[`''"]?\s*-ErrorAction'
        $getCommandMatches = [regex]::Matches($testContent, $getCommandPattern)
        foreach ($match in $getCommandMatches) {
            $funcName = $match.Groups[1].Value
            if (-not $allFunctions.ContainsKey($funcName)) {
                # Skip built-in cmdlets
                $isBuiltIn = $false
                
                # Check if it matches common PowerShell cmdlet patterns
                if ($funcName -match '^(Get|Set|New|Remove|Add|Clear|Copy|Move|Rename|Test|Out|Write|Read|Import|Export|ConvertTo|ConvertFrom|Select|Where|Sort|Group|Format|Measure|Compare|Start|Stop|Restart|Wait|Invoke|Enter|Exit|Push|Pop|Join|Split|Resolve|Update|Register|Unregister|Enable|Disable|Install|Uninstall|Save|Restore|Backup|Compress|Expand|Publish|Unpublish|Grant|Revoke|Block|Unblock|Protect|Unprotect|Initialize|Reset|Submit|Approve|Deny|Send|Receive|Connect|Disconnect|Suspend|Resume|Debug|Trace|Show|Hide|Lock|Unlock|Limit|Skip|Use)-\w+') {
                    $isBuiltIn = $true
                }
                
                # Check for specific known cmdlets
                elseif ($funcName -in @('New-Object', 'Get-Member', 'Add-Type', 'Using', 'New-Guid')) {
                    $isBuiltIn = $true
                }
                
                if (-not $isBuiltIn) {
                    $deprecatedFound[$funcName] = $true
                }
            }
        }
        
        # Add found deprecated references
        foreach ($funcName in $deprecatedFound.Keys) {
            # Skip ONLY Pester built-in commands and PowerShell language keywords
            # Do NOT skip functions that are mocked in tests but don't exist in our codebase
            if ($funcName -in @(
                # Pester commands
                'Should', 'Describe', 'Context', 'It', 'BeforeAll', 'BeforeEach', 'AfterAll', 'AfterEach',
                'Mock', 'Assert', 'InModuleScope',
                # PowerShell language keywords (not functions)
                'If', 'Else', 'ElseIf', 'For', 'ForEach', 'While', 'Do', 'Switch', 'Return', 'Break', 'Continue',
                'Try', 'Catch', 'Finally', 'Function', 'Filter', 'Class', 'Enum', 'Using', 'Param',
                'Begin', 'Process', 'End', 'DynamicParam', 'Hidden', 'Static', 'Public', 'Private',
                # Common parameter names that are definitely not functions
                'Path', 'LiteralPath', 'Name', 'Value', 'Force', 'Recurse', 'WhatIf', 'Confirm',
                'Verbose', 'Debug', 'ErrorAction', 'WarningAction', 'ErrorVariable',
                'PassThru', 'Scope', 'Module', 'Property', 'Filter', 'Include', 'Exclude',
                # PowerShell automatic variables
                'True', 'False', 'Null', 'PSScriptRoot', 'PSCommandPath', 'MyInvocation', 'PSBoundParameters')) {
                continue
            }
            
            if (-not $deprecatedTestReferences.ContainsKey($funcName)) {
                $deprecatedTestReferences[$funcName] = @()
            }
            if ($testFile.Name -notin $deprecatedTestReferences[$funcName]) {
                $deprecatedTestReferences[$funcName] += $testFile.Name
            }
        }
    }
    
    # Generate statistics
    $exportedFunctions = $allFunctions.GetEnumerator() | Where-Object { $_.Value.Exported }
    $internalFunctions = $allFunctions.GetEnumerator() | Where-Object { -not $_.Value.Exported }
    $testedExported = $exportedFunctions | Where-Object { $_.Value.Tested }
    $untestedExported = $exportedFunctions | Where-Object { -not $_.Value.Tested }
    $testedInternal = $internalFunctions | Where-Object { $_.Value.Tested }
    $untestedInternal = $internalFunctions | Where-Object { -not $_.Value.Tested }
    
    if ($CheckUsage) {
        $unusedExported = $exportedFunctions | Where-Object { -not $_.Value.UsedInCodebase }
        $unusedInternal = $internalFunctions | Where-Object { -not $_.Value.UsedInCodebase }
    } else {
        $unusedExported = @()
        $unusedInternal = @()
    }
    
    # Calculate coverage percentages
    $exportedCoverage = if ($exportedFunctions.Count -gt 0) { 
        [math]::Round(($testedExported.Count / $exportedFunctions.Count) * 100, 1) 
    } else { 0 }
    $internalCoverage = if ($internalFunctions.Count -gt 0) { 
        [math]::Round(($testedInternal.Count / $internalFunctions.Count) * 100, 1) 
    } else { 0 }
    $totalCoverage = [math]::Round((($testedExported.Count + $testedInternal.Count) / $allFunctions.Count) * 100, 1)
    
    # Display summary
    Write-Host ""
    Write-Host "=======================================" -ForegroundColor Yellow
    Write-Host "COVERAGE ANALYSIS SUMMARY" -ForegroundColor Yellow
    Write-Host "=======================================" -ForegroundColor Yellow
    Write-Host ""
    
    if ($ShowIndex) {
        Write-Host "INDEX:" -ForegroundColor Cyan
        Write-Host "  1. Function Statistics" -ForegroundColor Gray
        Write-Host "  2. Coverage Metrics" -ForegroundColor Gray
        Write-Host "  3. Untested Functions" -ForegroundColor Gray
        Write-Host "  4. Deprecated Test References" -ForegroundColor Gray
        Write-Host "  5. Module Breakdown" -ForegroundColor Gray
        if ($CheckUsage) {
            Write-Host "  6. Unused Functions" -ForegroundColor Gray
        }
        Write-Host ""
    }
    
    Write-Host "1. FUNCTION STATISTICS:" -ForegroundColor Cyan
    Write-Host "   Total Functions: $($allFunctions.Count)" -ForegroundColor White
    Write-Host "   - Exported: $($exportedFunctions.Count)" -ForegroundColor Green
    Write-Host "   - Internal: $($internalFunctions.Count)" -ForegroundColor Gray
    Write-Host ""
    Write-Host "   Test Files Analyzed: $testFilesAnalyzed" -ForegroundColor White
    Write-Host "   Total Test References: $totalTestReferences" -ForegroundColor White
    Write-Host ""
    
    Write-Host "2. COVERAGE METRICS:" -ForegroundColor Cyan
    $coverageColor = if ($totalCoverage -ge 80) { 'Green' } elseif ($totalCoverage -ge 60) { 'Yellow' } else { 'Red' }
    Write-Host "   Overall Coverage: $($totalCoverage)%" -ForegroundColor $coverageColor
    Write-Host "   - Exported: $($testedExported.Count)/$($exportedFunctions.Count) (${exportedCoverage}%)" -ForegroundColor Green
    Write-Host "   - Internal: $($testedInternal.Count)/$($internalFunctions.Count) (${internalCoverage}%)" -ForegroundColor Gray
    Write-Host ""
    
    # Show untested functions if ShowDetails
    if ($ShowDetails -and $untestedExported.Count -gt 0) {
        Write-Host "3. UNTESTED EXPORTED FUNCTIONS ($($untestedExported.Count)):" -ForegroundColor Red
        foreach ($func in @($untestedExported) | Sort-Object { $_.Value.Module }, { $_.Key }) {
            $usageInfo = if ($CheckUsage) {
                if ($func.Value.UsedInCodebase) {
                    " [USED]"
                } else {
                    " [UNUSED]"
                }
            } else { "" }
            Write-Host "   â€¢ $($func.Key) [$($func.Value.Module)]$usageInfo" -ForegroundColor Red
        }
        Write-Host ""
    }
    
    # Get test results if requested
    $testResults = @{}
    if ($IncludeTestResults) {
        Write-Host ""
        Write-Host "Phase 5: Loading test execution results..." -ForegroundColor Yellow
        $testResults = Get-TestResults -TestResultsPath $TestResultsPath
        Write-Host "  â€¢ Test results loaded: $($testResults.Count) functions with results" -ForegroundColor Gray
        
        # Debug: Show unmatched test results if verbose
        if ($VerbosePreference -eq 'Continue') {
            Write-Host ""
            Write-Host "DEBUG: Test Result Matching Analysis" -ForegroundColor Magenta
            $unmatchedTests = @()
            foreach ($funcName in $testResults.Keys) {
                if (-not $allFunctions.ContainsKey($funcName)) {
                    $unmatchedTests += $funcName
                }
            }
            
            if ($unmatchedTests.Count -gt 0) {
                Write-Host "  Unmatched test results (tests for non-existent functions):" -ForegroundColor Yellow
                foreach ($unmatched in $unmatchedTests | Sort-Object) {
                    $testCount = $testResults[$unmatched].Details.Count
                    Write-Host "    - $unmatched ($testCount tests)" -ForegroundColor Yellow
                }
            }
            
            Write-Host ""
            Write-Host "  Functions with test results:" -ForegroundColor Green
            $matchedCount = 0
            foreach ($funcName in $allFunctions.Keys | Sort-Object) {
                if ($testResults.ContainsKey($funcName)) {
                    $matchedCount++
                    $result = $testResults[$funcName]
                    Write-Host "    - $funcName (P:$($result.Passed) F:$($result.Failed) S:$($result.Skipped))" -ForegroundColor Green
                }
            }
            Write-Host "  Total matched: $matchedCount/$($allFunctions.Count) functions" -ForegroundColor Green
            Write-Host ""
        }
        
        # Integrate real test results with test details
        Write-Host ""
        Write-Host "Phase 5b: Merging real test results with coverage data..." -ForegroundColor Yellow
        foreach ($funcName in $testResults.Keys) {
            if ($allFunctions.ContainsKey($funcName)) {
                # Store the actual test results
                $allFunctions[$funcName].TestResults = $testResults[$funcName]
                
                # Merge with existing test details
                foreach ($testResult in $testResults[$funcName]) {
                    $key = "$($testResult.Describe) - $($testResult.It)"
                    if ($allFunctions[$funcName].TestDetails.ContainsKey($key)) {
                        # Update existing test detail with real result
                        $allFunctions[$funcName].TestDetails[$key].Status = $testResult.Status
                        $allFunctions[$funcName].TestDetails[$key].Duration = $testResult.Duration
                        $allFunctions[$funcName].TestDetails[$key].ErrorMessage = $testResult.ErrorMessage
                    } else {
                        # Add new test detail from real results
                        $allFunctions[$funcName].TestDetails[$key] = @{
                            Describe = $testResult.Describe
                            It = $testResult.It
                            Status = $testResult.Status
                            Duration = $testResult.Duration
                            ErrorMessage = $testResult.ErrorMessage
                            TestFiles = @($testResult.File)
                            Expectations = @()
                        }
                    }
                }
            }
        }
        Write-Host "  â€¢ Test results integrated successfully" -ForegroundColor Gray
    }
    
    # Generate report if requested
    if ($GenerateReport) {
        Write-Host "Generating coverage report..." -ForegroundColor Gray
        
        # Calculate dead test ratio for report
        $deadTestCalculation = @{
            ValidReferences = $totalTestReferences
            DeprecatedReferences = $deprecatedTestReferences.Count
            TotalReferences = $totalTestReferences + $deprecatedTestReferences.Count
            Percentage = if (($totalTestReferences + $deprecatedTestReferences.Count) -gt 0) {
                [math]::Round(($deprecatedTestReferences.Count / ($totalTestReferences + $deprecatedTestReferences.Count)) * 100, 1)
            } else { 0 }
        }
        
        # Get test execution totals from XML/JSON if available
        $testExecutionTotals = @{
            TotalTests = 0
            TotalPassed = 0
            TotalFailed = 0
            TotalSkipped = 0
        }
        
        if ($IncludeTestResults -and $TestResultsPath) {
            # Try JSON first
            $jsonPath = Join-Path $TestResultsPath "test-results-summary.json"
            if (Test-Path $jsonPath) {
                try {
                    $json = Get-Content $jsonPath -Raw | ConvertFrom-Json
                    $testExecutionTotals.TotalTests = $json.Overall.Total
                    $testExecutionTotals.TotalPassed = $json.Overall.Passed
                    $testExecutionTotals.TotalFailed = $json.Overall.Failed
                    $testExecutionTotals.TotalSkipped = if ($json.Overall.PSObject.Properties['Skipped']) { $json.Overall.Skipped } else { 0 }
                } catch {
                    # Fall back to XML parsing below
                }
            }
            
            # If no JSON data, try XML
            if ($testExecutionTotals.TotalTests -eq 0) {
                $xmlFiles = Get-ChildItem $TestResultsPath -Filter "*-TestResults.xml" -File -ErrorAction SilentlyContinue
                foreach ($xmlFile in $xmlFiles) {
                    try {
                        [xml]$xml = Get-Content $xmlFile.FullName -Raw
                        $root = $xml.SelectSingleNode("//test-results")
                        if ($root) {
                            $testExecutionTotals.TotalTests += [int]$root.GetAttribute("total")
                            $testExecutionTotals.TotalPassed += ([int]$root.GetAttribute("total") - [int]$root.GetAttribute("failures") - [int]$root.GetAttribute("not-run"))
                            $testExecutionTotals.TotalFailed += [int]$root.GetAttribute("failures")
                            $testExecutionTotals.TotalSkipped += [int]$root.GetAttribute("not-run")
                        }
                    } catch {
                        # Ignore individual file errors
                    }
                }
            }
        }
        
        $reportContent = Format-TestCoverageReport -CoverageData @{
            AllFunctions = $allFunctions
            FunctionsByModule = $functionsByModule
            DeprecatedTestReferences = $deprecatedTestReferences
            Statistics = @{
                TotalFunctions = $allFunctions.Count
                ExportedFunctions = $exportedFunctions.Count
                InternalFunctions = $internalFunctions.Count
                TestedExported = $testedExported.Count
                TestedInternal = $testedInternal.Count
                UntestedExported = $untestedExported.Count
                UntestedInternal = $untestedInternal.Count
                UnusedExported = $unusedExported.Count
                UnusedInternal = $unusedInternal.Count
                TotalCoverage = $totalCoverage
                ExportedCoverage = $exportedCoverage
                InternalCoverage = $internalCoverage
                DeprecatedTests = $deprecatedTestReferences.Count
                TestFilesAnalyzed = $testFilesAnalyzed
                TotalTestReferences = $totalTestReferences
            }
            UntestedExported = $untestedExported
            UnusedExported = $unusedExported
            UnusedInternal = $unusedInternal
            TestExecutionTotals = $testExecutionTotals
            CheckUsage = $CheckUsage
            IncludeTestResults = $IncludeTestResults
            TestResults = $testResults
            InvocationInfo = ""  # Placeholder for now
            Runtime = "0m0s"     # Placeholder for now
        } -DeadTestCalculation $deadTestCalculation -EnforcementData @{
            Phase = "Phase 2: New-Code-Only"
            CompliancePercentage = if ($allFunctions.Count -gt 0) { [math]::Round((($allFunctions.Count - $untestedExported.Count) / $allFunctions.Count) * 100, 1) } else { 0 }
            ExemptedCount = 28  # From TestCoverageExceptions.json
            GrandfatheredCount = 28
            PermanentExceptions = 1
            ActiveViolations = 0
            NextReviewDate = "2025-07-01"
            ExceptionTimeline = @{
                "2025-07-01" = 17
                "2025-08-01" = 2
                "2025-09-01" = 9
            }
        }
        
        # Write with UTF8 encoding without BOM
        [System.IO.File]::WriteAllText($OutputPath, $reportContent, [System.Text.Encoding]::UTF8)
        Write-Host ""
        Write-Host "Report saved to: $OutputPath" -ForegroundColor Green
    }
    
    # Return summary object
    return @{
        TotalFunctions = $allFunctions.Count
        ExportedFunctions = $exportedFunctions.Count
        InternalFunctions = $internalFunctions.Count
        TestedExported = $testedExported.Count
        TestedInternal = $testedInternal.Count
        UntestedExported = $untestedExported.Count
        UntestedInternal = $untestedInternal.Count
        UnusedExported = $unusedExported.Count
        UnusedInternal = $unusedInternal.Count
        TotalCoverage = $totalCoverage
        ExportedCoverage = $exportedCoverage
        InternalCoverage = $internalCoverage
        DeprecatedTests = $deprecatedTestReferences.Count
        TestFilesAnalyzed = $testFilesAnalyzed
        TotalTestReferences = $totalTestReferences
        AllFunctions = $allFunctions
    }
}


function Get-TestContext {
    <#
    .SYNOPSIS
        Extracts test context information from test content
    
    .DESCRIPTION
        Parses test file content to extract Describe/Context/It blocks
        that reference a specific function, including test expectations
    #>
    [CmdletBinding()]
    param(
        [string]$TestContent,
        [string]$FunctionName,
        [string]$TestFileName
    )
    
    $contexts = @()
    
    # Use a much simpler approach - find Context and It blocks independently
    # Find the Describe block title
    $describePattern = 'Describe\s+["'']([^"'']+)["'']'
    $describeMatch = [regex]::Match($TestContent, $describePattern)
    $describeTitle = if ($describeMatch.Success) { $describeMatch.Groups[1].Value } else { "Unknown" }
    
    # Only process if the test content mentions our function
    if ($TestContent -match "\b$FunctionName\b") {
        
        # Find all Context blocks
        $contextPattern = 'Context\s+["'']([^"'']+)["'']'
        $contextMatches = [regex]::Matches($TestContent, $contextPattern)
        
        # Find all It blocks
        $itPattern = 'It\s+["'']([^"'']+)["'']'
        $itMatches = [regex]::Matches($TestContent, $itPattern)
        
        # If we have Context blocks, pair them with It blocks
        if ($contextMatches.Count -gt 0) {
            foreach ($contextMatch in $contextMatches) {
                $contextTitle = $contextMatch.Groups[1].Value
                $contextStart = $contextMatch.Index
                
                # Find the next Context block or end of file to determine this Context's range
                $nextContextIndex = $TestContent.Length
                foreach ($nextContext in $contextMatches) {
                    if ($nextContext.Index -gt $contextStart -and $nextContext.Index -lt $nextContextIndex) {
                        $nextContextIndex = $nextContext.Index
                    }
                }
                
                # Find It blocks within this Context range
                $contextItBlocks = @()
                foreach ($itMatch in $itMatches) {
                    if ($itMatch.Index -gt $contextStart -and $itMatch.Index -lt $nextContextIndex) {
                        $contextItBlocks += $itMatch
                    }
                }
                
                # Create entries for each It block in this Context
                if ($contextItBlocks.Count -gt 0) {
                    foreach ($it in $contextItBlocks) {
                        $itTitle = $it.Groups[1].Value
                        
                        # Extract expectations (comprehensive)
                        $expectations = @()
                        $itContent = ""
                        
                        # Try to get the content after the It statement (larger window)
                        $itEnd = $it.Index + $it.Length
                        if ($itEnd -lt $TestContent.Length) {
                            $itContent = $TestContent.Substring($itEnd, [Math]::Min(1500, $TestContent.Length - $itEnd))
                            
                            # Comprehensive Should assertion parsing
                            $shouldMatches = [regex]::Matches($itContent, 'Should\s+(-\w+)(?:\s+([^;\n}]+))?')
                            foreach ($shouldMatch in $shouldMatches) {
                                $assertion = $shouldMatch.Groups[1].Value
                                $value = if ($shouldMatch.Groups[2].Success) { $shouldMatch.Groups[2].Value.Trim() } else { "" }
                                
                                switch ($assertion) {
                                    "-Be" { 
                                        if ($value -match '^\$?(true|false)$') {
                                            $expectations += "expects boolean result: $value"
                                        } elseif ($value -match '^\d+$') {
                                            $expectations += "expects numeric value: $value"
                                        } else {
                                            $expectations += "expects exact value: $value"
                                        }
                                    }
                                    "-BeExactly" { $expectations += "expects exact match: $value" }
                                    "-BeLike" { $expectations += "expects pattern match: $value" }
                                    "-BeOfType" { $expectations += "expects specific type: $value" }
                                    "-BeGreaterThan" { $expectations += "expects value greater than: $value" }
                                    "-BeLessThan" { $expectations += "expects value less than: $value" }
                                    "-BeNullOrEmpty" { $expectations += "expects null or empty result" }
                                    "-Contain" { $expectations += "expects output to contain: $value" }
                                    "-Match" { $expectations += "expects regex match: $value" }
                                    "-Exist" { $expectations += "expects file/path to exist" }
                                    "-Throw" { 
                                        if ($value) {
                                            $expectations += "expects exception: $value"
                                        } else {
                                            $expectations += "expects to throw any exception"
                                        }
                                    }
                                    "-Not" { 
                                        # Handle -Not assertions
                                        if ($itContent -match 'Should\s+-Not\s+-(\w+)(?:\s+([^;\n}]+))?') {
                                            $notAssertion = $matches[1]
                                            $notValue = if ($matches[2]) { $matches[2].Trim() } else { "" }
                                            $expectations += "expects NOT ${notAssertion}: ${notValue}"
                                        }
                                    }
                                    default { $expectations += "expects assertion: $assertion $value" }
                                }
                            }
                            
                            # Look for Mock assertions
                            $mockMatches = [regex]::Matches($itContent, 'Assert-MockCalled\s+(?:-CommandName\s+)?([A-Z][\w-]+)(?:\s+-Times\s+(\d+))?')
                            foreach ($mockMatch in $mockMatches) {
                                $mockCmd = $mockMatch.Groups[1].Value
                                $times = if ($mockMatch.Groups[2].Success) { $mockMatch.Groups[2].Value } else { "any number of" }
                                $expectations += "expects $mockCmd to be called $times times"
                            }
                            
                            # Look for parameter validation tests
                            if ($itContent -match 'ParameterArgumentValidationError') {
                                $expectations += "expects parameter validation error"
                            }
                            
                            # Look for specific error patterns
                            if ($itContent -match '-ErrorId\s+"([^"]+)"') {
                                $expectations += "expects specific error ID: $($matches[1])"
                            }
                            
                            # Look for file operations
                            if ($itContent -match 'Out-File|Set-Content|Add-Content') {
                                $expectations += "expects file write operation"
                            }
                            if ($itContent -match 'Get-Content|Test-Path') {
                                $expectations += "expects file read/check operation"
                            }
                        }
                        
                        $contexts += @{
                            Describe = $describeTitle
                            It = $itTitle
                            TestFile = $TestFileName
                            Expectations = $expectations
                        }
                    }
                } else {
                    # No It blocks found in this Context, use fallback
                    $contexts += @{
                        Describe = $describeTitle
                        It = "Tests within context ($contextTitle)"
                        TestFile = $TestFileName
                        Expectations = @()
                    }
                }
            }
        } else {
            # No Context blocks, look for standalone It blocks
            foreach ($itMatch in $itMatches) {
                $itTitle = $itMatch.Groups[1].Value
                
                # Extract expectations (comprehensive)
                $expectations = @()
                $itContent = ""
                
                # Try to get the content after the It statement (larger window)
                $itEnd = $itMatch.Index + $itMatch.Length
                if ($itEnd -lt $TestContent.Length) {
                    $itContent = $TestContent.Substring($itEnd, [Math]::Min(1500, $TestContent.Length - $itEnd))
                    
                    # Comprehensive Should assertion parsing
                    $shouldMatches = [regex]::Matches($itContent, 'Should\s+(-\w+)(?:\s+([^;\n}]+))?')
                    foreach ($shouldMatch in $shouldMatches) {
                        $assertion = $shouldMatch.Groups[1].Value
                        $value = if ($shouldMatch.Groups[2].Success) { $shouldMatch.Groups[2].Value.Trim() } else { "" }
                        
                        switch ($assertion) {
                            "-Be" { 
                                if ($value -match '^\$?(true|false)$') {
                                    $expectations += "expects boolean result: $value"
                                } elseif ($value -match '^\d+$') {
                                    $expectations += "expects numeric value: $value"
                                } else {
                                    $expectations += "expects exact value: $value"
                                }
                            }
                            "-BeExactly" { $expectations += "expects exact match: $value" }
                            "-BeLike" { $expectations += "expects pattern match: $value" }
                            "-BeOfType" { $expectations += "expects specific type: $value" }
                            "-BeGreaterThan" { $expectations += "expects value greater than: $value" }
                            "-BeLessThan" { $expectations += "expects value less than: $value" }
                            "-BeNullOrEmpty" { $expectations += "expects null or empty result" }
                            "-Contain" { $expectations += "expects output to contain: $value" }
                            "-Match" { $expectations += "expects regex match: $value" }
                            "-Exist" { $expectations += "expects file/path to exist" }
                            "-Throw" { 
                                if ($value) {
                                    $expectations += "expects exception: $value"
                                } else {
                                    $expectations += "expects to throw any exception"
                                }
                            }
                            "-Not" { 
                                # Handle -Not assertions
                                if ($itContent -match 'Should\s+-Not\s+-(\w+)(?:\s+([^;\n}]+))?') {
                                    $notAssertion = $matches[1]
                                    $notValue = if ($matches[2]) { $matches[2].Trim() } else { "" }
                                    $expectations += "expects NOT ${notAssertion}: ${notValue}"
                                }
                            }
                            default { $expectations += "expects assertion: $assertion $value" }
                        }
                    }
                    
                    # Look for Mock assertions
                    $mockMatches = [regex]::Matches($itContent, 'Assert-MockCalled\s+(?:-CommandName\s+)?([A-Z][\w-]+)(?:\s+-Times\s+(\d+))?')
                    foreach ($mockMatch in $mockMatches) {
                        $mockCmd = $mockMatch.Groups[1].Value
                        $times = if ($mockMatch.Groups[2].Success) { $mockMatch.Groups[2].Value } else { "any number of" }
                        $expectations += "expects $mockCmd to be called $times times"
                    }
                    
                    # Look for parameter validation tests
                    if ($itContent -match 'ParameterArgumentValidationError') {
                        $expectations += "expects parameter validation error"
                    }
                    
                    # Look for specific error patterns
                    if ($itContent -match '-ErrorId\s+"([^"]+)"') {
                        $expectations += "expects specific error ID: $($matches[1])"
                    }
                    
                    # Look for file operations
                    if ($itContent -match 'Out-File|Set-Content|Add-Content') {
                        $expectations += "expects file write operation"
                    }
                    if ($itContent -match 'Get-Content|Test-Path') {
                        $expectations += "expects file read/check operation"
                    }
                }
                
                $contexts += @{
                    Describe = $describeTitle
                    It = $itTitle
                    TestFile = $TestFileName
                    Expectations = $expectations
                }
            }
        }
    }
    
    # If still no contexts found but function is mentioned, create a fallback
    if ($contexts.Count -eq 0 -and $TestContent -match "\b$FunctionName\b") {
        $contexts += @{
            Describe = $describeTitle
            It = "Referenced in test file"
            TestFile = $TestFileName
            Expectations = @()
        }
    }
    
    return $contexts
}


function Format-TestCoverageReport {
    <#
    .SYNOPSIS
        Formats coverage data into a comprehensive markdown report
    
    .DESCRIPTION
        Takes coverage analysis data and generates a detailed markdown report
        with executive summary at the top followed by detailed analysis.
        Now includes enforcement status and compliance metrics.
    #>
    [CmdletBinding()]
    param(
        [hashtable]$CoverageData,
        [string]$Runtime = "N/A",
        [hashtable]$DeadTestCalculation = @{},
        [hashtable]$EnforcementData = @{}
    )
    
    $allFunctions = $CoverageData.AllFunctions
    $functionsByModule = $CoverageData.FunctionsByModule
    $deprecatedTestReferences = $CoverageData.DeprecatedTestReferences
    $stats = $CoverageData.Statistics
    $untestedExported = $CoverageData.UntestedExported
    $unusedExported = $CoverageData.UnusedExported
    $unusedInternal = $CoverageData.UnusedInternal
    $checkUsage = $CoverageData.CheckUsage
    $includeTestResults = $CoverageData.IncludeTestResults
    $testResults = $CoverageData.TestResults
    $invocationInfo = if ($CoverageData.InvocationInfo) { $CoverageData.InvocationInfo } else { "Invocation info unavailable" }
    $testExecutionTotals = $CoverageData.TestExecutionTotals
    
    # Calculate KPIs
    $totalDefined = $stats.TotalFunctions
    $deadFunctions = if ($checkUsage) { $stats.UnusedExported + $stats.UnusedInternal } else { 0 }
    $deadFunctionPercent = if ($totalDefined -gt 0) { [math]::Round(($deadFunctions / $totalDefined) * 100, 1) } else { 0 }
    
    $activeFunctions = $totalDefined - $deadFunctions
    $activeTested = if ($checkUsage) {
        # Ensure variables are treated as collections
        $unusedExportedCollection = @($unusedExported)
        $unusedInternalCollection = @($unusedInternal)
        ($stats.TestedExported + $stats.TestedInternal) - 
        (($unusedExportedCollection | Where-Object { $_.Value.Tested }).Count + 
         ($unusedInternalCollection | Where-Object { $_.Value.Tested }).Count)
    } else {
        $stats.TestedExported + $stats.TestedInternal
    }
    $activeCoverage = if ($activeFunctions -gt 0) { [math]::Round(($activeTested / $activeFunctions) * 100, 1) } else { 0 }
    
    # Use provided calculation or calculate it
    if (-not $DeadTestCalculation -or $DeadTestCalculation.Count -eq 0) {
        # Calculate dead test ratio - ratio of deprecated references to total references
        # This measures how much of our test code references non-existent functions
        $validTestReferences = $stats.TotalTestReferences  # References to functions that exist
        $deprecatedTestReferences = $stats.DeprecatedTests # References to functions that don't exist
        $totalReferences = $validTestReferences + $deprecatedTestReferences
        
        $deadTestPercent = if ($totalReferences -gt 0) { 
            [math]::Round(($deprecatedTestReferences / $totalReferences) * 100, 1) 
        } else { 0 }
        
        # Store calculation details for the report
        $deadTestCalculation = @{
            ValidReferences = $validTestReferences
            DeprecatedReferences = $deprecatedTestReferences
            TotalReferences = $totalReferences
            Percentage = $deadTestPercent
        }
    } else {
        $deadTestPercent = $DeadTestCalculation.Percentage
        $deadTestCalculation = $DeadTestCalculation
    }
    
    
    # Use provided test execution totals if available, otherwise calculate from details
    if ($testExecutionTotals -and $testExecutionTotals.TotalTests -gt 0) {
        # Use the accurate totals from XML/JSON
        $totalTests = $testExecutionTotals.TotalTests
        $totalPassed = $testExecutionTotals.TotalPassed
        $totalFailed = $testExecutionTotals.TotalFailed
        $totalSkipped = $testExecutionTotals.TotalSkipped
    } else {
        # Fall back to calculating from test details (may be incomplete)
        $totalPassed = 0
        $totalFailed = 0
        $totalSkipped = 0
        $totalTests = 0
        
        if ($includeTestResults -and $testResults) {
            foreach ($funcResults in $testResults.Values) {
                if ($funcResults.Details) {
                    foreach ($detail in $funcResults.Details) {
                        $totalTests++
                        switch ($detail.Result) {
                            "Success" { $totalPassed++ }
                            "Failure" { $totalFailed++ }
                            "Ignored" { $totalSkipped++ }
                            "Skipped" { $totalSkipped++ }
                        }
                    }
                }
            }
        }
    }
    
    # Test execution summary is now handled by New-TestCoverageReport function
    $testExecutionSummary = ""
    
    # Get enforcement data if not provided
    if (-not $EnforcementData -or $EnforcementData.Count -eq 0) {
        # Load exception data
        $exceptionPath = Join-Path (Split-Path $script:ModulePath -Parent) "TestCoverageExceptions.json"
        if (Test-Path $exceptionPath) {
            try {
                $exceptions = ConvertFrom-JsonToHashtable -Json (Get-Content $exceptionPath -Raw)
                $EnforcementData = @{
                    Exceptions = $exceptions
                    GrandfatheredCount = $exceptions.grandfathered.Count
                    PermanentCount = $exceptions.permanent.Count
                    NextReviewDate = $exceptions.metadata.next_review
                }
            } catch {
                $EnforcementData = @{}
            }
        }
    }
    
    # Calculate documentation completeness metrics
    $docStats = @{
        Documented = 0
        FullyDocumented = 0
        PartiallyDocumented = 0
        Undocumented = 0
        TotalScore = 0
        TotalFunctions = 0
    }
    
    foreach ($func in $allFunctions.Values) {
        # Only count exported functions for documentation metrics
        if ($func.Exported) {
            $docStats.TotalFunctions++
            
            if ($func.Documentation -and $func.Documentation.HasDocumentation) {
                $docStats.Documented++
                $docStats.TotalScore += $func.Documentation.CompletionScore
                
                if ($func.Documentation.CompletionScore -ge 75) {
                    $docStats.FullyDocumented++
                } else {
                    $docStats.PartiallyDocumented++
                }
            } else {
                $docStats.Undocumented++
            }
        }
    }
    
    $docCompleteness = if ($docStats.TotalFunctions -gt 0) {
        [math]::Round(($docStats.Documented / $docStats.TotalFunctions) * 100, 1)
    } else { 0 }
    
    $avgDocScore = if ($docStats.Documented -gt 0) {
        [math]::Round($docStats.TotalScore / $docStats.Documented, 1)
    } else { 0 }
    
    # Calculate enforcement compliance metrics
    $enforcementMetrics = @{
        NewCodeCompliance = "100%"  # Default for new code
        GrandfatheredViolations = if ($EnforcementData.GrandfatheredCount) { $EnforcementData.GrandfatheredCount } else { 0 }
        PermanentExceptions = if ($EnforcementData.PermanentCount) { $EnforcementData.PermanentCount } else { 0 }
        EnforcementLevel = "Phase 2: New-Code-Only"
        ComplianceRate = $stats.ExportedCoverage
    }
    
    # Start building the report with executive summary at the top
    $report = @"
# UpdateLoxone Test Coverage Report

Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') (Runtime: $Runtime) | $invocationInfo$testExecutionSummary
**Enforcement Level:** $($enforcementMetrics.EnforcementLevel) | **Compliance Status:** $($enforcementMetrics.ComplianceRate)% compliant

## Key Performance Indicators (KPIs)

| Metric | Value | Status |
|--------|-------|--------|
| **Test Success Rate** | $(if ($totalPassed + $totalFailed -gt 0) { [math]::Round(($totalPassed / ($totalPassed + $totalFailed)) * 100, 1) } else { 0 })% ($totalPassed/$(if ($totalPassed + $totalFailed -gt 0) { $totalPassed + $totalFailed } else { 1 })) | $(if ($totalPassed + $totalFailed -eq 0) { "N/A" } elseif ($totalPassed + $totalFailed -gt 0 -and ($totalPassed / ($totalPassed + $totalFailed)) -ge 0.8) { "Good" } elseif ($totalPassed + $totalFailed -gt 0 -and ($totalPassed / ($totalPassed + $totalFailed)) -ge 0.6) { "Fair" } else { "Poor" }) |
| **Active Function Coverage** | $activeCoverage% ($activeTested/$activeFunctions) | $(if ($activeCoverage -ge 80) { "Good" } elseif ($activeCoverage -ge 60) { "Fair" } else { "Poor" }) |
| **Dead Code Ratio** | $deadFunctionPercent% ($deadFunctions/$totalDefined functions) | $(if ($deadFunctionPercent -le 10) { "Good" } elseif ($deadFunctionPercent -le 30) { "Fair" } else { "Poor" }) |
| **Dead Test Ratio** | $deadTestPercent% ($($deadTestCalculation.DeprecatedReferences)/$($deadTestCalculation.TotalReferences) refs) | $(if ($deadTestPercent -le 10) { "Good" } elseif ($deadTestPercent -le 20) { "Fair" } else { "Poor" }) |
| **Documentation Coverage** | $docCompleteness% ($($docStats.Documented)/$($docStats.TotalFunctions) exported) | $(if ($docCompleteness -ge 80) { "Excellent" } elseif ($docCompleteness -ge 60) { "Good" } elseif ($docCompleteness -ge 40) { "Fair" } else { "Poor" }) |
| **Enforcement Compliance** | $($enforcementMetrics.ComplianceRate)% ($($enforcementMetrics.GrandfatheredViolations) exempted) | $(if ($enforcementMetrics.ComplianceRate -ge 90) { "Excellent" } elseif ($enforcementMetrics.ComplianceRate -ge 80) { "Good" } elseif ($enforcementMetrics.ComplianceRate -ge 60) { "Fair" } else { "Needs Work" }) |

### KPI Calculation Formulas

- **Test Success Rate** = (Passed Tests) / (Passed Tests + Failed Tests) * 100
  - Measures the percentage of tests that pass out of all tests that ran
  - Does not include skipped tests in the calculation
  
- **Active Function Coverage** = (Tested Functions in Active Code) / (Total Active Functions) * 100
  - Active functions are those actually used in the codebase (not dead code)
  
- **Dead Code Ratio** = (Unused Functions) / (Total Functions) * 100  
  - Functions defined but never called anywhere in the codebase
  
- **Dead Test Ratio** = (Deprecated Function References) / (Total Function References) * 100
  - Measures what percentage of function references in tests point to non-existent functions
  - Formula: Deprecated function refs / (Valid function refs + Deprecated function refs)
  - Calculation: $($deadTestCalculation.DeprecatedReferences) / ($($deadTestCalculation.ValidReferences) + $($deadTestCalculation.DeprecatedReferences)) = $deadTestPercent%
  
- **Documentation Coverage** = (Documented Exported Functions) / (Total Exported Functions) * 100
  - Measures what percentage of exported functions have comment-based help documentation
  - Average documentation completeness: $avgDocScore%
  - Fully documented (75%+): $($docStats.FullyDocumented), Partially: $($docStats.PartiallyDocumented), Missing: $($docStats.Undocumented)
  
Note: This compares function references (102 valid + 95 deprecated = 197 total), not test cases (313 executed).

### Test Execution Context

- **Test Cases Executed**: $($totalPassed + $totalFailed) (from XML results)
- **Test Cases Skipped**: $totalSkipped (includes system tests when not running as admin)
- **Total Test Cases**: $totalTests

## Executive Summary

**Overall Coverage: $($stats.TotalCoverage)%** | Exported: $($stats.ExportedCoverage)% | Internal: $($stats.InternalCoverage)%

### Quick Stats
- **Total Functions**: $($stats.TotalFunctions) (Exported: $($stats.ExportedFunctions), Internal: $($stats.InternalFunctions))
- **Test Coverage**: $($stats.TestedExported + $stats.TestedInternal)/$($stats.TotalFunctions) functions tested
- **Test Files**: $($stats.TestFilesAnalyzed) files analyzed
- **Test References**: $($stats.TotalTestReferences) function references found
- **Documentation**: $($docStats.Documented)/$($stats.ExportedFunctions) exported functions documented (avg $avgDocScore% complete)$(if ($includeTestResults -and $testResults.Count -gt 0) {
    # Note: These totals were already calculated above for the header
    "`n- **Test Execution**: $totalTests tests ($totalPassed passed, $totalFailed failed, $totalSkipped skipped)"
} else {
    "`n- **Test Execution**: Not available (coverage analysis only)"
})

### Critical Issues
1. **Untested Exported Functions**: $($stats.UntestedExported) functions need tests
2. **Untested Internal Functions**: $($stats.UntestedInternal) functions need tests  
3. **Deprecated Test References**: $($stats.DeprecatedTests) references to non-existent functions
$(if ($checkUsage) { "4. **Unused Functions**: $($stats.UnusedExported) exported, $($stats.UnusedInternal) internal functions unused" })

### Enforcement Status

| Category | Count | Details |
|----------|-------|---------|
| **Grandfathered Violations** | $($enforcementMetrics.GrandfatheredViolations) | Functions exempted until expiration dates |
| **Permanent Exceptions** | $($enforcementMetrics.PermanentExceptions) | Functions permanently exempted (meta-functions) |
| **Active Violations** | $(($stats.UntestedExported) - $enforcementMetrics.GrandfatheredViolations - $enforcementMetrics.PermanentExceptions) | Functions requiring immediate tests |
| **Next Review Date** | $(if ($EnforcementData.NextReviewDate) { $EnforcementData.NextReviewDate } else { "Not set" }) | Next exception expiration review |

### Action Items
- **Immediate**: Write tests for the $($stats.UntestedExported) untested exported functions
- **Consider**: Write tests for the $($stats.UntestedInternal) untested internal functions (lower priority)
- **Short-term**: Clean up $($stats.DeprecatedTests) deprecated test references
- **Goal**: Achieve 90%+ coverage for exported functions (currently $($stats.ExportedCoverage)%)
- **Enforcement**: $(if ($enforcementMetrics.GrandfatheredViolations -gt 0) { "Review $($enforcementMetrics.GrandfatheredViolations) grandfathered exceptions by their expiration dates" } else { "All violations actively enforced" })

---

## Detailed Analysis

### Coverage by Function Type

| Category | Tested | Total | Coverage |
|----------|--------|-------|----------|
| Exported Functions | $($stats.TestedExported) | $($stats.ExportedFunctions) | $($stats.ExportedCoverage)% |
| Internal Functions | $($stats.TestedInternal) | $($stats.InternalFunctions) | $($stats.InternalCoverage)% |
| **Total** | **$(($stats.TestedExported + $stats.TestedInternal))** | **$($stats.TotalFunctions)** | **$($stats.TotalCoverage)%** |

### Untested Exported Functions ($($stats.UntestedExported))

These functions are part of the public API but lack test coverage:

| Function | Module | Enforcement Status | Expiration |
|----------|--------|-------------------|------------|
"@

    foreach ($func in @($untestedExported) | Sort-Object { $_.Value.Module }, { $_.Key }) {
        $funcName = $func.Key
        $enforcementStatus = "âŒ Required"
        $expiration = "Now"
        
        # Check if function has exception
        if ($EnforcementData.Exceptions) {
            if ($EnforcementData.Exceptions.grandfathered.ContainsKey($funcName)) {
                $exception = $EnforcementData.Exceptions.grandfathered[$funcName]
                $enforcementStatus = "âš ï¸ Grandfathered"
                $expiration = $exception.expires
            } elseif ($EnforcementData.Exceptions.permanent.ContainsKey($funcName)) {
                $enforcementStatus = "âœ… Permanent Exception"
                $expiration = "Never"
            }
        }
        
        $report += "`n| ``$($funcName)`` | $($func.Value.Module) | $enforcementStatus | $expiration |"
    }
    
    # Add untested internal functions section
    $untestedInternal = $CoverageData.AllFunctions.GetEnumerator() | Where-Object { -not $_.Value.Exported -and -not $_.Value.Tested }
    if ($untestedInternal.Count -gt 0) {
        $report += @"

### Untested Internal Functions ($($untestedInternal.Count))

These internal functions lack test coverage:

| Function | Module | Usage Status |
|----------|--------|--------------|
"@
        foreach ($func in @($untestedInternal) | Sort-Object { $_.Value.Module }, { $_.Key }) {
            $usageStatus = if ($checkUsage) {
                if ($func.Value.UsedInCodebase) {
                    "Used in: $($func.Value.UsageLocations -join ', ')"
                } else {
                    "**UNUSED - candidate for removal**"
                }
            } else { "Not analyzed" }
            $report += "`n| ``$($func.Key)`` | $($func.Value.Module) | $usageStatus |"
        }
    }
    
    # Add module breakdown
    $report += @"

### Module Breakdown

| Module | Total | Tested | Coverage | Exported | Internal |
|--------|-------|--------|----------|----------|----------|
"@

    foreach ($module in $functionsByModule.GetEnumerator() | Sort-Object Key) {
        $moduleName = $module.Key
        $moduleFuncs = $module.Value
        $moduleTotal = $moduleFuncs.Count
        $moduleTested = ($moduleFuncs | Where-Object { $allFunctions[$_].Tested }).Count
        $moduleExported = ($moduleFuncs | Where-Object { $allFunctions[$_].Exported }).Count
        $moduleInternal = $moduleTotal - $moduleExported
        $moduleCoverage = if ($moduleTotal -gt 0) { 
            [math]::Round(($moduleTested / $moduleTotal) * 100, 1) 
        } else { 0 }
        
        $report += "`n| $moduleName | $moduleTotal | $moduleTested | $moduleCoverage% | $moduleExported | $moduleInternal |"
    }
    
    # Add detailed function coverage section
    $report += @"

### Tested Functions Detail

"@

    # Initialize detailed status counters to verify against header totals
    $detailPassCount = 0
    $detailFailCount = 0
    $detailSkipCount = 0
    $detailNotRunCount = 0
    $detailTotalCount = 0

    foreach ($module in $functionsByModule.GetEnumerator() | Sort-Object Key) {
        $moduleName = $module.Key
        $testedFuncs = $module.Value | Where-Object { $allFunctions[$_].Tested } | Sort-Object
        
        if ($testedFuncs.Count -gt 0) {
            $report += @"

#### $moduleName

"@
            foreach ($funcName in $testedFuncs) {
                $func = $allFunctions[$funcName]
                $exportedTag = if ($func.Exported) { "**[Exported]**" } else { "*[Internal]*" }
                $report += "`n**``$funcName``** $exportedTag"
                
                # Add function documentation if available
                if ($func.Documentation -and $func.Documentation.HasDocumentation) {
                    $doc = $func.Documentation
                    $docCompleteness = "$($doc.CompletionScore)%"
                    $report += " - Documentation: $docCompleteness complete"
                    
                    if ($doc.Synopsis) {
                        $report += "`n   - **Synopsis:** $($doc.Synopsis)"
                    }
                    if ($doc.Description -and $doc.Description -ne $doc.Synopsis) {
                        # Truncate long descriptions
                        $desc = if ($doc.Description.Length -gt 200) {
                            $doc.Description.Substring(0, 197) + "..."
                        } else {
                            $doc.Description
                        }
                        $report += "`n   - **Description:** $desc"
                    }
                } else {
                    $report += " - **Documentation:** âš ï¸ Missing"
                }
                
                
                # Add test result summary if available
                if ($includeTestResults -and $func.TestResults) {
                    # Use the integrated real test results
                    $passCount = 0
                    $failCount = 0
                    $skipCount = 0
                    $totalTime = 0
                    
                    foreach ($result in $func.TestResults) {
                        switch ($result.Status) {
                            "Passed" { $passCount++ }
                            "Failed" { $failCount++ }
                            "Skipped" { $skipCount++ }
                        }
                        if ($result.Duration) {
                            $totalTime += [double]$result.Duration
                        }
                    }
                    
                    $totalTests = $passCount + $failCount + $skipCount
                    $resultText = " - Test Results: "
                    if ($failCount -gt 0) {
                        $resultText += '**FAILED** ('
                    } else {
                        $resultText += '**PASSED** ('
                    }
                    $resultText += "$passCount passed"
                    if ($failCount -gt 0) {
                        $resultText += ", $failCount failed"
                    }
                    if ($skipCount -gt 0) {
                        $resultText += ", $skipCount skipped"
                    }
                    $resultText += ")"
                    if ($totalTime -gt 0) {
                        $resultText += " in $([math]::Round($totalTime, 2))s"
                    }
                    $report += $resultText
                } elseif ($includeTestResults -and $testResults.ContainsKey($funcName)) {
                    $result = $testResults[$funcName]
                    $totalTests = $result.Passed + $result.Failed + $result.Skipped
                    $resultText = " - Test Results: "
                    if ($result.Failed -gt 0) {
                        $resultText += '<span style="color: red;">**FAILED**</span> ('
                    } else {
                        $resultText += '<span style="color: green;">**PASSED**</span> ('
                    }
                    $resultText += '<span style="color: green;">' + $result.Passed + ' passed</span>'
                    if ($result.Failed -gt 0) {
                        $resultText += ', <span style="color: red;">' + $result.Failed + ' failed</span>'
                    }
                    if ($result.Skipped -gt 0) {
                        $resultText += ', <span style="color: orange;">' + $result.Skipped + ' skipped</span>'
                    }
                    $resultText += ")"
                    if ($result.TotalTime -gt 0) {
                        $resultText += " in $([math]::Round($result.TotalTime, 2))s"
                    }
                    $report += $resultText
                }
                $report += "`n"
                
                if ($func.TestDetails.Count -gt 0) {
                    $report += "`n**Test Coverage Details:**`n"
                    
                    # Process each test with its full context
                    $testNumber = 1
                    foreach ($testKey in $func.TestDetails.Keys | Sort-Object) {
                        $detail = $func.TestDetails[$testKey]
                        $testFiles = $detail.TestFiles -join ', '
                        
                        # Get test result if available
                        $testStatus = "[NOT RUN]"  # Default status
                        $testTime = ""
                        $errorMessage = ""
                        
                        if ($includeTestResults -and $func.TestResults) {
                            # Try to match by test description from integrated test results
                            $matchingResult = $func.TestResults | Where-Object { 
                                # Match exact It block description
                                $_.It -eq $detail.It -or
                                # Match by combined Describe.It pattern
                                $_.Name -eq "$($detail.Describe).$($detail.It)" -or
                                # Match if test name contains the It description
                                $_.It -like "*$($detail.It)*" -or
                                $_.Name -like "*$($detail.It)*"
                            } | Select-Object -First 1
                            
                            if ($matchingResult) {
                                $testStatus = switch ($matchingResult.Status) {
                                    "Passed" { "[PASS]" }
                                    "Failed" { "[FAIL]" }
                                    "Skipped" { "[SKIP]" }
                                    default { "[UNKNOWN]" }
                                }
                                if ($matchingResult.Duration) {
                                    $testTime = " ($($matchingResult.Duration)s)"
                                }
                                if ($matchingResult.ErrorMessage) {
                                    $errorMessage = $matchingResult.ErrorMessage
                                }
                            }
                        } elseif ($includeTestResults -and $testResults.ContainsKey($funcName)) {
                            # Fallback to old test results format if no integrated results
                            $matchingResult = $testResults[$funcName].Details | Where-Object { 
                                # Match exact It block description
                                $_.TestName -eq $detail.It -or
                                # Match partial It block description (in case of truncation)
                                $_.TestName -like "*$($detail.It)*" -or 
                                # Match using the full name from XML if available
                                ($_.FullName -and (
                                    # Match the combined Describe.It format from XML
                                    $_.FullName -eq "$($detail.Describe).$($detail.It)" -or
                                    # Match if full name contains both Describe and It parts
                                    ($_.FullName -like "*$($detail.Describe)*" -and $_.FullName -like "*$($detail.It)*")
                                ))
                            } | Select-Object -First 1
                            
                            if ($matchingResult) {
                                $testStatus = switch ($matchingResult.Result) {
                                    "Success" { "[PASS]" }
                                    "Failure" { "[FAIL]" }
                                    "Ignored" { "[SKIP]" }
                                    "Skipped" { "[SKIP]" }
                                    default { "[UNKNOWN]" }
                                }
                                if ($matchingResult.Time) {
                                    $testTime = " (${matchingResult.Time}s)"
                                }
                            }
                        }
                        
                        # Count test status for verification
                        $detailTotalCount++
                        switch ($testStatus) {
                            "[PASS]" { $detailPassCount++ }
                            "[FAIL]" { $detailFailCount++ }
                            "[SKIP]" { $detailSkipCount++ }
                            "[NOT RUN]" { $detailNotRunCount++ }
                        }
                        
                        # Color the test name based on its status
                        $testNameFormatted = if ($testStatus) {
                            switch ($testStatus) {
                                "[PASS]" { "`n$testNumber. **Test:** $($detail.It) **[PASSED]**`n" }
                                "[FAIL]" { "`n$testNumber. **Test:** $($detail.It) **[FAILED]**`n" }
                                "[SKIP]" { "`n$testNumber. **Test:** $($detail.It) **[SKIPPED]**`n" }
                                "[NOT RUN]" { "`n$testNumber. **Test:** $($detail.It) **[NOT RUN]**`n" }
                                default { "`n$testNumber. **Test:** $($detail.It)`n" }
                            }
                        } else {
                            "`n$testNumber. **Test:** $($detail.It)`n"
                        }
                        $report += $testNameFormatted
                        $report += "   - **File:** $testFiles`n"
                        $report += "   - **Context:** $($detail.Describe)`n"
                        
                        # Always add status
                        $statusDisplay = switch ($testStatus) {
                            "[PASS]" { '**PASS**' }
                            "[FAIL]" { '**FAIL**' }
                            "[SKIP]" { '**SKIP**' }
                            "[NOT RUN]" { '**NOT RUN**' }
                            default { '**UNKNOWN**' }
                        }
                        $report += "   - **Status:** $statusDisplay$testTime`n"
                        
                        # Add error message if test failed
                        if ($errorMessage -and $testStatus -eq "[FAIL]") {
                            # Truncate long error messages
                            $shortError = if ($errorMessage.Length -gt 150) {
                                $errorMessage.Substring(0, 147) + "..."
                            } else {
                                $errorMessage
                            }
                            $report += "   - **Error:** $shortError`n"
                        }
                        
                        # Check for individual assertion results from TestTracking
                        $assertionResults = @{}
                        $hasAssertionTracking = $false
                        
                        # Try to get assertion tracking results if available
                        # First check if results are available in memory
                        if (Get-Command Get-TestAssertionResults -ErrorAction SilentlyContinue) {
                            $testKey = "$funcName.$($detail.It)"
                            $assertionData = Get-TestAssertionResults -TestName $detail.It -FunctionName $funcName
                            if ($assertionData -and $assertionData.Assertions) {
                                $hasAssertionTracking = $true
                                # Index assertions by their description/expectation
                                foreach ($assertion in $assertionData.Assertions) {
                                    $assertionResults[$assertion.Description] = $assertion.Passed
                                }
                            }
                        }
                        
                        # If no in-memory results, try to load from file
                        if (-not $hasAssertionTracking -and $includeTestResults -and $TestResultsPath) {
                            # Look for assertion results JSON files
                            $assertionFiles = @()
                            if (Test-Path $TestResultsPath) {
                                $assertionFiles = Get-ChildItem -Path $TestResultsPath -Filter "*-AssertionResults.json" -File -ErrorAction SilentlyContinue
                            }
                            
                            foreach ($file in $assertionFiles) {
                                try {
                                    $assertionDataFromFile = Get-Content $file.FullName -Raw | ConvertFrom-Json
                                    # Look for our specific test
                                    foreach ($testEntry in $assertionDataFromFile.PSObject.Properties) {
                                        if ($testEntry.Value.TestName -eq $detail.It -and $testEntry.Value.FunctionName -eq $funcName) {
                                            $hasAssertionTracking = $true
                                            foreach ($assertion in $testEntry.Value.Assertions) {
                                                $assertionResults[$assertion.Description] = $assertion.Passed
                                            }
                                            break
                                        }
                                    }
                                    if ($hasAssertionTracking) { break }
                                } catch {
                                    # Ignore file read errors
                                }
                            }
                        }
                        
                        # Add expectations/goals if available
                        if ($detail.Expectations -and $detail.Expectations.Count -gt 0) {
                            $report += "   - **Test Goals:**`n"
                            foreach ($expectation in $detail.Expectations) {
                                # Check if we have individual assertion results
                                $goalIndicator = '-'
                                $hasIndividualResult = $false
                                
                                if ($hasAssertionTracking) {
                                    # Use advanced pattern matching from TestTracking module
                                    if (Get-Command Find-AssertionMatch -ErrorAction SilentlyContinue) {
                                        $match = Find-AssertionMatch -Goal $expectation -AssertionResults $assertionResults -ReturnBestMatch
                                        if ($match -and $match.Score -ge 40) {  # Minimum confidence threshold
                                            $hasIndividualResult = $true
                                            $goalIndicator = if ($assertionResults[$match.AssertionDescription]) {
                                                '**[PASS]**'
                                            } else {
                                                '**[FAIL]**'
                                            }
                                        }
                                    } else {
                                        # Fallback to simple matching if advanced matching not available
                                        foreach ($desc in $assertionResults.Keys) {
                                            if ($desc -like "*$expectation*" -or $expectation -like "*$desc*") {
                                                $hasIndividualResult = $true
                                                $goalIndicator = if ($assertionResults[$desc]) {
                                                    '**[PASS]**'
                                                } else {
                                                    '**[FAIL]**'
                                                }
                                                break
                                            }
                                        }
                                    }
                                }
                                
                                if (-not $hasIndividualResult) {
                                    # Fall back to overall test status only if test was actually run
                                    $goalIndicator = if ($testStatus -and $testStatus -ne "[NOT RUN]") {
                                        switch ($testStatus) {
                                            "[PASS]" { '**[PASS]**' }
                                            "[FAIL]" { '**[FAIL]**' }
                                            "[SKIP]" { '**[SKIP]**' }
                                            default { '-' }
                                        }
                                    } else {
                                        '-'
                                    }
                                }
                                
                                $report += "     - $goalIndicator $expectation`n"
                            }
                        } else {
                            # Try to extract goals from the test description
                            if ($detail.It -match '\[(.+)\]') {
                                $report += "   - **Test Goals:**`n"
                                $goals = $matches[1] -split ';'
                                foreach ($goal in $goals) {
                                    # Check if we have individual assertion results
                                    $goalIndicator = '-'
                                    $hasIndividualResult = $false
                                    
                                    if ($hasAssertionTracking) {
                                        # Try to match goal with assertion results
                                        foreach ($desc in $assertionResults.Keys) {
                                            if ($desc -like "*$($goal.Trim())*" -or $goal.Trim() -like "*$desc*") {
                                                $hasIndividualResult = $true
                                                $goalIndicator = if ($assertionResults[$desc]) {
                                                    '**[PASS]**'
                                                } else {
                                                    '**[FAIL]**'
                                                }
                                                break
                                            }
                                        }
                                    }
                                    
                                    if (-not $hasIndividualResult) {
                                        # Fall back to overall test status only if test was actually run
                                        $goalIndicator = if ($testStatus -and $testStatus -ne "[NOT RUN]") {
                                            switch ($testStatus) {
                                                "[PASS]" { '**[PASS]**' }
                                                "[FAIL]" { '**[FAIL]**' }
                                                "[SKIP]" { '**[SKIP]**' }
                                                default { '-' }
                                            }
                                        } else {
                                            '-'
                                        }
                                    }
                                    
                                    $report += "     - $goalIndicator $($goal.Trim())`n"
                                }
                            }
                        }
                        
                        $testNumber++
                    }
                } else {
                    $report += "- Referenced in tests but no specific test cases found`n"
                }
                $report += "`n"
            }
        }
    }
    
    # Add test status summary from detailed section
    if ($detailTotalCount -gt 0) {
        $report += @"

### Test Status Summary (from Details)

| Status | Count | Percentage |
|--------|-------|------------|
| **PASSED** | $detailPassCount | $([math]::Round(($detailPassCount / $detailTotalCount) * 100, 1))% |
| **FAILED** | $detailFailCount | $([math]::Round(($detailFailCount / $detailTotalCount) * 100, 1))% |
| **SKIPPED** | $detailSkipCount | $([math]::Round(($detailSkipCount / $detailTotalCount) * 100, 1))% |
| **NOT RUN** | $detailNotRunCount | $([math]::Round(($detailNotRunCount / $detailTotalCount) * 100, 1))% |
| **Total** | **$detailTotalCount** | **100%** |

"@
    }
    
    # Add comprehensive cleanup section
    # Ensure variables are collections before accessing .Count
    $unusedExportedList = @($unusedExported)
    $unusedInternalList = @($unusedInternal)
    $totalCleanupItems = $unusedExportedList.Count + $unusedInternalList.Count + $deprecatedTestReferences.Count
    
    if ($totalCleanupItems -gt 0) {
        $report += @"

### Code Cleanup Recommendations

Total items to clean up: **$totalCleanupItems**

#### Functions to Remove ($($unusedExportedList.Count + $unusedInternalList.Count) total)

These functions are not used anywhere in the UpdateLoxone codebase:

| Function | Module | Type | Tested | Action |
|----------|--------|------|--------|--------|
"@
        # First add unused exported functions
        foreach ($func in $unusedExportedList | Sort-Object { $_.Value.Module }, { $_.Key }) {
            $tested = if ($func.Value.Tested) { "Yes" } else { "No" }
            $action = if ($func.Value.Tested) {
                "Remove function + tests"
            } else {
                "**Remove immediately**"
            }
            $report += "`n| ``$($func.Key)`` | $($func.Value.Module) | Exported | $tested | $action |"
        }
        
        # Then add unused internal functions
        foreach ($func in $unusedInternalList | Sort-Object { $_.Value.Module }, { $_.Key }) {
            $tested = if ($func.Value.Tested) { "Yes" } else { "No" }
            $action = if ($func.Value.Tested) {
                "Remove function + tests"
            } else {
                "**Remove immediately**"
            }
            $report += "`n| ``$($func.Key)`` | $($func.Value.Module) | Internal | $tested | $action |"
        }
        
        # Add deprecated test references
        if ($deprecatedTestReferences.Count -gt 0) {
            # Count total occurrences
            $totalOccurrences = 0
            foreach ($ref in $deprecatedTestReferences.Values) {
                $totalOccurrences += $ref.Count
            }
            
            $report += @"

#### Test References to Remove ($($deprecatedTestReferences.Count) unique functions, $totalOccurrences total occurrences)

These function calls in test files reference non-existent functions:

| Referenced Function | Test Files | Occurrences | Action |
|---------------------|------------|-------------|--------|
"@
            foreach ($ref in $deprecatedTestReferences.GetEnumerator() | Sort-Object { $_.Value.Count } -Descending) {
                $testFilesList = $ref.Value -join ', '
                if ($testFilesList.Length -gt 60) {
                    $testFilesList = $testFilesList.Substring(0, 57) + "..."
                }
                $report += "`n| ``$($ref.Key)`` | $testFilesList | $($ref.Value.Count) | Clean up test files |"
            }
            
            $report += @"

##### Deprecated Test Analysis
- **Unique deprecated functions**: $($deprecatedTestReferences.Count)
- **Total occurrences across test files**: $totalOccurrences
- **Average occurrences per function**: $([math]::Round($totalOccurrences / $deprecatedTestReferences.Count, 1))
"@
        }
    }
    
    # Add cleanup summary
    if ($totalCleanupItems -gt 0) {
        $testedButUnused = ($unusedExportedList | Where-Object { $_.Value.Tested }).Count + 
                          ($unusedInternalList | Where-Object { $_.Value.Tested }).Count
        $untestedAndUnused = ($unusedExportedList | Where-Object { -not $_.Value.Tested }).Count + 
                            ($unusedInternalList | Where-Object { -not $_.Value.Tested }).Count
        
        $report += @"

### Cleanup Summary

**Total cleanup required: $totalCleanupItems items**
- **$($unusedExportedList.Count + $unusedInternalList.Count) unused functions** to remove
  - $untestedAndUnused functions with no tests (remove immediately)
  - $testedButUnused functions with tests (remove function + tests)
- **$($deprecatedTestReferences.Count) test references** to non-existent functions to clean up

Since this module is only used internally within UpdateLoxone, all unused functions can be safely removed.

"@
    }
    
    # Add enforcement summary at the end
    $report += @"

---

## Enforcement System Status

### Current Implementation Phase
**$($enforcementMetrics.EnforcementLevel)**

### Features Available
- âœ… **Exception Management**: Grandfathering system for existing violations
- âœ… **New-Code Validation**: Prevents new untested code via pre-commit hooks
- âœ… **CI/CD Integration**: Automated compliance checking in pipelines
- âœ… **Helper Tools**: Test stub generation and compliance checking
- âœ… **Compliance Reporting**: Enhanced reports with enforcement details

### Enforcement Tools
- ``Test-CoverageCompliance``: Full compliance validation
- ``Test-NewCodeCompliance``: New code only validation  
- ``New-TestStub``: Generate test templates
- ``Test-FunctionCoverage``: Check specific functions
- ``Get-ComplianceViolations``: Module-level analysis

### Exception Timeline
$(if ($EnforcementData.Exceptions -and $EnforcementData.Exceptions.grandfathered) {
    $expirations = @()
    $grouped = $EnforcementData.Exceptions.grandfathered.GetEnumerator() | Group-Object { $_.Value.expires }
    foreach ($group in $grouped | Sort-Object Name) {
        $expirations += "- **$($group.Name)**: $($group.Count) exceptions expire"
    }
    $expirations -join "`n"
} else {
    "- No grandfathered exceptions found"
})

### Next Steps
$(if ($enforcementMetrics.GrandfatheredViolations -gt 0) {
    "1. Start writing tests for functions expiring soon`n2. Use ``New-TestStub`` to generate test templates`n3. Monitor compliance with ``Test-CoverageCompliance -ShowViolations``"
} else {
    "1. Maintain 100% compliance for new code`n2. Consider enabling stricter enforcement`n3. Target internal functions for improved coverage"
})
"@
    
    return $report
}


function Get-TestResults {
    <#
    .SYNOPSIS
        Loads test results from the most recent test run
    
    .DESCRIPTION
        Reads test result files to get pass/fail/skip status for each test
    #>
    [CmdletBinding()]
    param(
        [string]$TestResultsPath
    )
    
    $testResults = @{}
    
    # Try to find the most recent test results
    if (-not $TestResultsPath) {
        # Try multiple possible locations for test results
        $possiblePaths = @(
            (Join-Path (Split-Path $script:TestPath -Parent) "tests\TestResults"),
            (Join-Path $script:TestPath "TestResults"),
            (Join-Path (Get-Location) "tests\TestResults")
        )
        
        foreach ($path in $possiblePaths) {
            if (Test-Path $path) {
                # Get most recent TestRun folder
                $mostRecent = Get-ChildItem $path -Filter "TestRun_*" -Directory -ErrorAction SilentlyContinue | 
                              Sort-Object LastWriteTime -Descending | 
                              Select-Object -First 1
                if ($mostRecent) {
                    $TestResultsPath = $mostRecent.FullName
                    break
                }
            }
        }
    }
    
    if ($TestResultsPath -and (Test-Path $TestResultsPath)) {
        # Load test results from XML files
        $xmlFiles = Get-ChildItem $TestResultsPath -Filter "*-TestResults.xml" -File
        
        foreach ($xmlFile in $xmlFiles) {
            try {
                [xml]$xml = Get-Content $xmlFile.FullName -Raw
                
                # Parse test results - Pester NUnit format
                $testCases = $xml.SelectNodes("//test-case")
                foreach ($testCase in $testCases) {
                    $testName = $testCase.GetAttribute("name")
                    $description = $testCase.GetAttribute("description")
                    $result = $testCase.GetAttribute("result")
                    $success = $testCase.GetAttribute("success")
                    $time = $testCase.GetAttribute("time")
                    
                    # Extract function name from test name or description
                    $functionName = $null
                    
                    # First try to extract from the test name
                    if ($testName -match '^([A-Z][\w-]+)(?:\s+(?:Function|Command|Cmdlet))?\.' ) {
                        $functionName = $matches[1]
                    }
                    # Also try nested describe blocks
                    elseif ($testName -match '^([A-Z][\w-]+)\s+(?:Function|Command|Cmdlet)\.') {
                        $functionName = $matches[1]
                    }
                    # Try to extract from a pattern like "FunctionName Core Functionality.Description"
                    elseif ($testName -match '^([A-Z][\w-]+)\s+Core\s+Functionality\.') {
                        $functionName = $matches[1]
                    }
                    # If that fails, try a more general pattern
                    elseif ($testName -match '([A-Z][\w-]+)') {
                        # Get the first PascalCase/hyphenated word that looks like a PowerShell function
                        $functionName = $matches[1]
                    }
                    
                    # Store test result details
                    if ($functionName) {
                        if (-not $testResults.ContainsKey($functionName)) {
                            $testResults[$functionName] = @{
                                Passed = 0
                                Failed = 0
                                Skipped = 0
                                TotalTime = 0
                                Details = @()
                            }
                        }
                        
                        # Map NUnit result status to our format
                        if ($success -eq "True") {
                            $testResults[$functionName].Passed++
                        } elseif ($result -eq "Failure") {
                            $testResults[$functionName].Failed++
                        } elseif ($result -eq "Ignored" -or $result -eq "Skipped") {
                            $testResults[$functionName].Skipped++
                        }
                        
                        if ($time) {
                            $testResults[$functionName].TotalTime += [double]$time
                        }
                        
                        # Extract test context (Describe/It blocks)
                        $testParts = $testName -split '\.'
                        $describe = if ($testParts.Count -gt 1) { $testParts[0] } else { $functionName }
                        $it = if ($testParts.Count -gt 1) { $testParts[1..($testParts.Count-1)] -join '.' } else { $description }
                        
                        $testResults[$functionName].Details += @{
                            TestName = $description
                            FullName = $testName
                            Result = $result
                            Time = $time
                            Success = $success
                            DescribeBlock = $describe
                            ItBlock = $it
                        }
                    }
                }
            } catch {
                Write-Verbose "Failed to parse $($xmlFile.Name): $_"
            }
        }
    }
    
    return $testResults
}


function New-TestCoverageReport {
    <#
    .SYNOPSIS
        Generates a comprehensive test coverage report
    
    .DESCRIPTION
        Generates a single coverage report that includes both executive summary
        and detailed analysis in one file
    
    .PARAMETER CheckUsage
        Include function usage analysis in the report
    
    .PARAMETER ShowConsole
        Display summary information in the console
    
    .PARAMETER OutputDirectory
        Directory where report will be saved
        
    .PARAMETER TestResultsPath
        Path to directory containing test results (XML files and JSON summary)
        
    .PARAMETER IncludeTestResults
        Include test run results (pass/fail/skip) in the report
        
    .PARAMETER TestRunId
        Test run ID timestamp to use for coverage report filename (format: yyyyMMdd-HHmmss)
    
    .EXAMPLE
        New-TestCoverageReport -ShowConsole -IncludeTestResults
    #>
    [CmdletBinding()]
    param(
        [switch]$CheckUsage,
        [switch]$ShowConsole,
        [string]$OutputDirectory,
        [string]$TestResultsPath,
        [switch]$IncludeTestResults,
        [string]$TestRunId
    )
    
    # Track start time for runtime calculation
    $startTime = Get-Date
    
    # Get invocation information early while call stack is available
    $invocationInfo = ""
    $callingScript = ""
    
    try {
        $callStack = Get-PSCallStack
        if ($callStack.Count -gt 1) {
            # Look for the script that called us (skip the current function)
            for ($i = 1; $i -lt $callStack.Count; $i++) {
                $caller = $callStack[$i]
                if ($caller.ScriptName -and $caller.ScriptName -ne $MyInvocation.ScriptName) {
                    $callingScript = Split-Path $caller.ScriptName -Leaf
                    $invocationInfo = "Invoked by: **$callingScript**"
                    if ($caller.FunctionName -and $caller.FunctionName -ne '<ScriptBlock>') {
                        $invocationInfo += " â†’ $($caller.FunctionName)"
                    }
                    break
                }
            }
        }
        
        # If no calling script found, check command line
        if (-not $callingScript) {
            $commandLine = (Get-WmiObject Win32_Process -Filter "ProcessId = $PID" -ErrorAction SilentlyContinue).CommandLine
            if ($commandLine -match '\\([^\\]+\.ps1)(.*)') {
                $callingScript = $matches[1]
                $params = $matches[2].Trim()
                if ($params) {
                    $invocationInfo = "Invoked by: **$callingScript** with parameters: $params"
                } else {
                    $invocationInfo = "Invoked by: **$callingScript**"
                }
            } else {
                $invocationInfo = "Invoked directly or interactively"
            }
        }
        
        # Add test execution context from environment variables
        $testContext = ""
        if ($env:UPDATELOXONE_TEST_TYPE) {
            $testContext = " | Test Type: **$($env:UPDATELOXONE_TEST_TYPE)**"
        }
        if ($env:UPDATELOXONE_RUN_CATEGORIES) {
            $testContext += " | Categories: **$($env:UPDATELOXONE_RUN_CATEGORIES)**"
        }
        if ($env:UPDATELOXONE_IS_ADMIN -eq 'True') {
            $testContext += " | **Running as Administrator**"
        } else {
            $testContext += " | Running as User"
        }
        if ($env:UPDATELOXONE_SKIP_SYSTEM -eq 'True') {
            $testContext += " | Skip System: True"
        }
        $invocationInfo += $testContext
    } catch {
        $invocationInfo = "Invocation info unavailable"
    }
    
    # Set up output directory
    if (-not $OutputDirectory) {
        # Try multiple fallback options for output directory
        if ($script:TestPath -and (Test-Path $script:TestPath)) {
            $OutputDirectory = Join-Path $script:TestPath "TestResults"
        } elseif (Test-Path "$PSScriptRoot\..\tests") {
            $OutputDirectory = Join-Path "$PSScriptRoot\..\tests" "TestResults"
        } else {
            # Ultimate fallback - use temp directory
            $OutputDirectory = Join-Path $env:TEMP "UpdateLoxone_TestResults"
            Write-Warning "Using temporary directory for coverage output: $OutputDirectory"
        }
    }
    
    # Set up test results path if not provided
    if (-not $TestResultsPath -and $IncludeTestResults) {
        # Try to find the most recent test results
        $resultsBase = $OutputDirectory
        if (Test-Path $resultsBase) {
            # Get most recent TestRun folder
            $mostRecent = Get-ChildItem $resultsBase -Filter "TestRun_*" -Directory | 
                          Sort-Object LastWriteTime -Descending | 
                          Select-Object -First 1
            if ($mostRecent) {
                $TestResultsPath = $mostRecent.FullName
            }
        }
    }
    
    # Validate output directory path
    if ([string]::IsNullOrWhiteSpace($OutputDirectory)) {
        throw "OutputDirectory is null or empty. Cannot generate coverage report."
    }
    
    # Create coverage subdirectory
    $coverageDir = Join-Path $OutputDirectory "coverage"
    if (-not (Test-Path $coverageDir)) {
        New-Item -ItemType Directory -Path $coverageDir -Force | Out-Null
    }
    
    # Use provided TestRunId or generate new timestamp
    $timestamp = if ($TestRunId) { $TestRunId } else { Get-Date -Format 'yyyyMMdd-HHmmss' }
    
    Write-Host "Generating Test Coverage Report..." -ForegroundColor Cyan
    Write-Host ""
    
    # First run analysis to get KPIs for filename
    $tempReportPath = Join-Path $OutputDirectory "temp_coverage.md"
    
    # Execute coverage analysis in a script block to capture invocation context
    $coverageParams = @{
        GenerateReport = $false  # We'll generate it ourselves with proper context
        CheckUsage = $CheckUsage
        ShowIndex = $true
        ShowDetails = $true
        IncludeTestResults = $IncludeTestResults
        TestResultsPath = if ($TestResultsPath) { $TestResultsPath } else { $OutputDirectory }
    }
    
    $coverageResult = Get-TestCoverage @coverageParams
    
    # Calculate runtime
    $runtime = (Get-Date) - $startTime
    $runtimeMinutes = [math]::Floor($runtime.TotalMinutes)
    $runtimeSeconds = [math]::Floor($runtime.TotalSeconds) % 60
    $runtimeFormatted = "{0}m{1}s" -f $runtimeMinutes, $runtimeSeconds
    
    # Calculate KPIs for filename
    $totalFunctions = $coverageResult.TotalFunctions
    $deadFunctions = $coverageResult.UnusedExported + $coverageResult.UnusedInternal
    $activeFunctions = $totalFunctions - $deadFunctions
    
    # Calculate active tested (tested functions that are not dead code)
    $testedExported = $coverageResult.TestedExported
    $testedInternal = $coverageResult.TestedInternal
    $totalTested = $testedExported + $testedInternal
    
    # For active coverage, we use total coverage if no usage analysis, otherwise active coverage
    if ($CheckUsage -and $activeFunctions -gt 0) {
        # Need to calculate how many tested functions are actually used
        # This is approximate since we don't have the detailed data here
        $activeCoverage = [math]::Round(($totalTested / $totalFunctions) * 100, 0)
    } else {
        $activeCoverage = if ($totalFunctions -gt 0) { 
            [math]::Round(($totalTested / $totalFunctions) * 100, 0) 
        } else { 0 }
    }
    
    # Calculate dead code ratio (unused functions)
    $deadCodeRatio = if ($totalFunctions -gt 0) {
        [math]::Round(($deadFunctions / $totalFunctions) * 100, 0)
    } else { 0 }
    
    $deadTestRatio = if (($coverageResult.TotalTestReferences + $coverageResult.DeprecatedTests) -gt 0) {
        [math]::Round(($coverageResult.DeprecatedTests / ($coverageResult.TotalTestReferences + $coverageResult.DeprecatedTests)) * 100, 0)
    } else { 0 }
    
    # Calculate test execution coverage and success rate if we have test results
    $testExecutionCoverage = 0
    $testSuccessRate = 0
    $totalTestCount = 0
    $totalSkipped = 0
    if ($IncludeTestResults -and $TestResultsPath) {
        # Try to get test results from JSON summary
        $jsonSummaryPath = Join-Path $TestResultsPath "test-results-summary.json"
        if (Test-Path $jsonSummaryPath) {
            try {
                $jsonSummary = Get-Content $jsonSummaryPath -Raw | ConvertFrom-Json
                $totalTestCount = $jsonSummary.Overall.Total
                $passedTests = $jsonSummary.Overall.Passed
                $failedTests = $jsonSummary.Overall.Failed
                $totalSkipped = if ($jsonSummary.Overall.PSObject.Properties['Skipped']) { $jsonSummary.Overall.Skipped } else { 0 }
                if ($totalTestCount -gt 0) {
                    # Test execution coverage = (Passed + Failed) / Total * 100
                    # We count failed tests as "executed" since they ran, just didn't pass
                    $executedTests = $passedTests + $failedTests
                    $testExecutionCoverage = [math]::Round(($executedTests / $totalTestCount) * 100, 0)
                    
                    # Test success rate = Passed / (Passed + Failed) * 100
                    if ($executedTests -gt 0) {
                        $testSuccessRate = [math]::Round(($passedTests / $executedTests) * 100, 0)
                    }
                }
            } catch {
                # Fall back to zeros if JSON parsing fails
            }
        }
    }
    
    # Format KPIs with leading zeros
    # New format: TTTT-EEE-SSS-FFF-DDD-TTT where:
    # TTTT = Total test count (4 digits)
    # EEE = Test execution coverage % (3 digits)
    # SSS = Test success rate % (3 digits)
    # FFF = Function coverage % (3 digits)
    # DDD = Dead code ratio % (3 digits)
    # TTT = Dead test ratio % (3 digits)
    $kpiString = "{0:D4}-{1:D3}-{2:D3}-{3:D3}-{4:D3}-{5:D3}" -f $totalTestCount, [int]$testExecutionCoverage, [int]$testSuccessRate, [int]$activeCoverage, [int]$deadCodeRatio, [int]$deadTestRatio
    
    # Create final filename with timestamp and KPIs
    $finalReportName = "coverage_${timestamp}_${kpiString}.md"
    $reportPath = Join-Path $coverageDir $finalReportName
    
    # Now generate the report with all proper context
    Write-Host "Generating detailed coverage report..." -ForegroundColor Gray
    
    # Re-run with report generation to get all the detailed data
    $null = Get-TestCoverage `
        -GenerateReport `
        -CheckUsage:$CheckUsage `
        -OutputPath $tempReportPath `
        -ShowIndex `
        -ShowDetails `
        -IncludeTestResults:$IncludeTestResults `
        -TestResultsPath $(if ($TestResultsPath) { $TestResultsPath } else { $OutputDirectory })
    
    # Update report with runtime and invocation information
    $reportContent = Get-Content $tempReportPath -Raw
    
    # Load test execution data to add to header
    $testExecutionInfo = ""
    if ($IncludeTestResults) {
        # Use TestResultsPath if provided, otherwise fall back to OutputDirectory
        $testDataPath = if ($TestResultsPath) { $TestResultsPath } else { $OutputDirectory }
        
        # First try to read from JSON summary for most accurate results
        $jsonSummaryPath = Join-Path $testDataPath "test-results-summary.json"
        if (Test-Path $jsonSummaryPath) {
            try {
                $jsonSummary = Get-Content $jsonSummaryPath -Raw | ConvertFrom-Json
                $totalPassed = $jsonSummary.Overall.Passed
                $totalFailed = $jsonSummary.Overall.Failed
                $totalSkipped = if ($jsonSummary.Overall.PSObject.Properties['Skipped']) { $jsonSummary.Overall.Skipped } else { 0 }
                $totalTests = $jsonSummary.Overall.Total
                
                # Calculate total time from all test categories
                $totalTime = 0
                if ($jsonSummary.UnitTests.Duration) {
                    $unitDuration = [TimeSpan]::Parse($jsonSummary.UnitTests.Duration)
                    $totalTime += $unitDuration.TotalSeconds
                }
                if ($jsonSummary.IntegrationTests.Duration) {
                    $integrationDuration = [TimeSpan]::Parse($jsonSummary.IntegrationTests.Duration)
                    $totalTime += $integrationDuration.TotalSeconds
                }
                if ($jsonSummary.SystemTests.Duration) {
                    $systemDuration = [TimeSpan]::Parse($jsonSummary.SystemTests.Duration)
                    $totalTime += $systemDuration.TotalSeconds
                }
                
                $testExecutionInfo = "`n**Test Execution Results:** $totalTests tests total ($totalPassed passed, $totalFailed failed, $totalSkipped skipped) in $([math]::Round($totalTime, 2))s"
            } catch {
                # Fall back to XML parsing if JSON fails
                $testExecutionInfo = $null
            }
        }
        
        # If no JSON or it failed, fall back to XML parsing
        if ($null -eq $testExecutionInfo -or [string]::IsNullOrWhiteSpace($testExecutionInfo)) {
            # Look for test result XML files
            $xmlFiles = @()
            if (Test-Path $testDataPath) {
                $xmlFiles = Get-ChildItem $testDataPath -Filter "*-TestResults.xml" -File -ErrorAction SilentlyContinue
            }
            
            if ($xmlFiles.Count -gt 0) {
                $totalTests = 0
                $totalPassed = 0
                $totalFailed = 0
                $totalSkipped = 0
                $totalTime = 0
                
                foreach ($xmlFile in $xmlFiles) {
                    try {
                        [xml]$xml = Get-Content $xmlFile.FullName -Raw
                        $testSuite = $xml.SelectSingleNode("//test-suite[@type='Assembly']")
                        if ($testSuite) {
                            $total = [int]$testSuite.GetAttribute("total")
                            $passed = [int]$testSuite.GetAttribute("passed")
                            $failed = [int]$testSuite.GetAttribute("failed")
                            $skipped = [int]$testSuite.GetAttribute("skipped")
                            $time = [double]$testSuite.GetAttribute("time")
                            
                            $totalTests += $total
                            $totalPassed += $passed
                            $totalFailed += $failed
                            $totalSkipped += $skipped
                            $totalTime += $time
                        }
                    } catch {
                        # Ignore errors reading individual files
                    }
                }
                
                if ($totalTests -gt 0) {
                    $testExecutionInfo = "`n**Test Execution Results:** $totalTests tests total ($totalPassed passed, $totalFailed failed, $totalSkipped skipped) in $([math]::Round($totalTime, 2))s"
                }
            }
        }
    }
    
    # Create filename breakdown explanation
    $filenameBreakdown = @"

**Report Filename:** ``$finalReportName``
- **$($totalTestCount.ToString().PadLeft(4, '0'))** total tests
- **$([int]$testExecutionCoverage)%** test execution coverage ($($totalTestCount - $totalSkipped) of $totalTestCount tests ran)
- **$([int]$testSuccessRate)%** test success rate ($totalPassed/$($totalTestCount - $totalSkipped))
- **$([int]$activeCoverage)%** function coverage
- **$([int]$deadCodeRatio)%** dead code ratio
- **$([int]$deadTestRatio)%** dead test ratio
"@
    
    # Add TestRun information if available
    $testRunInfo = ""
    if ($TestResultsPath -and (Test-Path $TestResultsPath)) {
        # Extract TestRun ID from path
        if ($TestResultsPath -match 'TestRun_(\d{8}-\d{6})') {
            $testRunId = $matches[1]
            $testRunInfo = "`n**TestRun:** TestRun_$testRunId"
        }
    }
    
    # Fix the header to include invocation info, runtime, and test execution
    $newHeader = @"
# UpdateLoxone Test Coverage Report

Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') (Runtime: $runtimeFormatted) | $invocationInfo$testExecutionInfo$testRunInfo
$filenameBreakdown
"@
    
    # Replace the header
    $reportContent = $reportContent -replace '# UpdateLoxone Test Coverage Report\s*\n\s*Generated: [^\n]+', $newHeader
    
    # Write with UTF8 encoding without BOM
    [System.IO.File]::WriteAllText($reportPath, $reportContent, [System.Text.Encoding]::UTF8)
    
    # Remove temp file
    Remove-Item $tempReportPath -Force -ErrorAction SilentlyContinue
    
    # Also clean up old coverage.md files in root directory
    $oldCoverageFile = Join-Path $OutputDirectory "coverage.md"
    if (Test-Path $oldCoverageFile) {
        Remove-Item $oldCoverageFile -Force -ErrorAction SilentlyContinue
    }
    
    if ($ShowConsole) {
        Write-Host "`n========================================" -ForegroundColor Yellow
        Write-Host "COVERAGE SUMMARY" -ForegroundColor Yellow
        Write-Host "========================================" -ForegroundColor Yellow
        $coverageColor = if ($coverageResult.TotalCoverage -ge 80) { 'Green' } 
                        elseif ($coverageResult.TotalCoverage -ge 60) { 'Yellow' } 
                        else { 'Red' }
        Write-Host "Overall Coverage: $($coverageResult.TotalCoverage)%" -ForegroundColor $coverageColor
        
        $untestedColor = if ($coverageResult.UntestedExported -eq 0) { 'Green' }
                        elseif ($coverageResult.UntestedExported -le 5) { 'Yellow' }
                        else { 'Red' }
        Write-Host "Untested Exported Functions: $($coverageResult.UntestedExported)" -ForegroundColor $untestedColor
        
        $deprecatedColor = if ($coverageResult.DeprecatedTests -eq 0) { 'Green' } else { 'Yellow' }
        Write-Host "Deprecated Test References: $($coverageResult.DeprecatedTests)" -ForegroundColor $deprecatedColor
    }
    
    # Console output is handled by calling script to avoid duplication
    $kpiDisplay = $kpiString -replace '-', '/'
    
    # Return paths for integration with other scripts
    return @{
        ReportPath = $reportPath
        Timestamp = $timestamp
        CoverageResult = $coverageResult
        Runtime = $runtimeFormatted
        KPIs = $kpiDisplay
    }
}


function Test-CoverageCompliance {
    <#
    .SYNOPSIS
        Validates test coverage compliance against established rules
    
    .DESCRIPTION
        Checks that all exported functions have corresponding test coverage
        and validates naming conventions. Can operate in different modes
        for gradual enforcement.
    
    .PARAMETER ChangedFunctions
        Only validate these specific functions (for new code validation)
        
    .PARAMETER StrictMode
        Enforce all rules without exceptions (for CI)
        
    .PARAMETER ExceptionFile
        Path to JSON file containing grandfathered exceptions
        
    .PARAMETER ShowViolations
        Display detailed violation information
        
    .EXAMPLE
        Test-CoverageCompliance -ShowViolations
        Validates all exported functions and shows violations
        
    .EXAMPLE
        Test-CoverageCompliance -ChangedFunctions @("Write-Log", "Get-Version") 
        Only validates specific functions (for pre-commit)
        
    .EXAMPLE
        Test-CoverageCompliance -StrictMode
        Full enforcement mode for CI pipeline
    #>
    [CmdletBinding()]
    param(
        [string[]]$ChangedFunctions = @(),
        [switch]$StrictMode,
        [string]$ExceptionFile = "TestCoverageExceptions.json",
        [switch]$ShowViolations
    )
    
    Write-Host "Testing Coverage Compliance..." -ForegroundColor Cyan
    
    # Get current coverage data using existing infrastructure
    $coverageData = Get-TestCoverage -IncludeTestResults:$false
    
    # Load exceptions if file exists
    $exceptions = @{
        grandfathered = @{}
        permanent = @{}
    }
    
    $exceptionPath = Join-Path (Split-Path $PSScriptRoot -Parent) $ExceptionFile
    if (Test-Path $exceptionPath) {
        try {
            $exceptions = ConvertFrom-JsonToHashtable -Json (Get-Content $exceptionPath -Raw)
        } catch {
            Write-Warning "Could not load exception file: $ExceptionFile"
        }
    }
    
    # Validation results
    $violations = @()
    $warnings = @()
    $compliantFunctions = 0
    $totalValidated = 0
    
    # Rule 1: Every exported function must have a test file
    foreach ($funcName in $coverageData.AllFunctions.Keys) {
        $func = $coverageData.AllFunctions[$funcName]
        
        # Only check exported functions
        if (-not $func.Exported) { continue }
        
        # If ChangedFunctions specified, only check those
        if ($ChangedFunctions.Count -gt 0 -and $funcName -notin $ChangedFunctions) {
            continue
        }
        
        $totalValidated++
        $moduleName = $func.Module
        
        # Check if function has exception
        $hasException = $false
        $exceptionReason = ""
        
        if ($exceptions.grandfathered.ContainsKey($funcName)) {
            $exception = $exceptions.grandfathered[$funcName]
            $expirationDate = [DateTime]::Parse($exception.expires)
            if ($expirationDate -gt (Get-Date)) {
                $hasException = $true
                $exceptionReason = "Grandfathered: $($exception.reason) (expires $($exception.expires))"
            } else {
                $warnings += "Expired exception for $funcName - was grandfathered until $($exception.expires)"
            }
        } elseif ($exceptions.permanent.ContainsKey($funcName)) {
            $hasException = $true
            $exceptionReason = "Permanent exception: $($exceptions.permanent[$funcName].reason)"
        }
        
        # Skip validation if has valid exception and not in strict mode
        if ($hasException -and -not $StrictMode) {
            if ($ShowViolations) {
                Write-Host "  âš ï¸  $funcName - $exceptionReason" -ForegroundColor Yellow
            }
            continue
        }
        
        # Validate test coverage
        $hasViolation = $false
        $violationDetails = @()
        
        # Check if function is tested
        if (-not $func.Tested) {
            $hasViolation = $true
            $violationDetails += "No test coverage found"
        }
        
        # Check test file naming convention
        $expectedTestFile = "$moduleName.Tests.ps1"
        $testFileExists = $false
        
        if ($func.TestDetails) {
            foreach ($detail in $func.TestDetails.Values) {
                $testFiles = $detail.TestFiles
                foreach ($testFile in $testFiles) {
                    if ($testFile -like "*$expectedTestFile") {
                        $testFileExists = $true
                        break
                    }
                }
                if ($testFileExists) { break }
            }
        }
        
        if (-not $testFileExists) {
            $hasViolation = $true
            $violationDetails += "Expected test file '$expectedTestFile' not found"
        }
        
        # Check Describe block naming convention
        if ($func.TestDetails) {
            $hasCorrectDescribe = $false
            foreach ($detail in $func.TestDetails.Values) {
                $expectedDescribe = "$funcName Function"
                if ($detail.Describe -eq $expectedDescribe -or $detail.Describe -like "*$funcName*") {
                    $hasCorrectDescribe = $true
                    break
                }
            }
            
            if (-not $hasCorrectDescribe) {
                $violationDetails += "Expected Describe block '$funcName Function' not found"
            }
        }
        
        # Record results
        if ($hasViolation) {
            $violations += @{
                Function = $funcName
                Module = $moduleName
                Details = $violationDetails
                HasException = $hasException
                ExceptionReason = $exceptionReason
            }
            
            if ($ShowViolations) {
                Write-Host "  âŒ $funcName [$moduleName]" -ForegroundColor Red
                foreach ($detail in $violationDetails) {
                    Write-Host "     - $detail" -ForegroundColor Red
                }
            }
        } else {
            $compliantFunctions++
            if ($ShowViolations) {
                Write-Host "  âœ… $funcName [$moduleName]" -ForegroundColor Green
            }
        }
    }
    
    # Summary
    $complianceRate = if ($totalValidated -gt 0) { 
        [math]::Round(($compliantFunctions / $totalValidated) * 100, 1) 
    } else { 100 }
    
    Write-Host "`nCompliance Summary:" -ForegroundColor Cyan
    Write-Host "  Functions validated: $totalValidated"
    Write-Host "  Compliant: $compliantFunctions"
    Write-Host "  Violations: $($violations.Count)"
    Write-Host "  Warnings: $($warnings.Count)"
    Write-Host "  Compliance rate: $complianceRate%" -ForegroundColor $(if ($complianceRate -ge 90) { 'Green' } elseif ($complianceRate -ge 70) { 'Yellow' } else { 'Red' })
    
    if ($warnings.Count -gt 0) {
        Write-Host "`nWarnings:" -ForegroundColor Yellow
        foreach ($warning in $warnings) {
            Write-Host "  âš ï¸  $warning" -ForegroundColor Yellow
        }
    }
    
    # Return results
    $result = @{
        Compliant = ($violations.Count -eq 0)
        TotalValidated = $totalValidated
        CompliantFunctions = $compliantFunctions
        Violations = $violations
        Warnings = $warnings
        ComplianceRate = $complianceRate
    }
    
    if ($violations.Count -gt 0 -and $StrictMode) {
        throw "Coverage compliance failed: $($violations.Count) violations found"
    }
    
    return $result
}


function Get-ChangedFunctions {
    <#
    .SYNOPSIS
        Gets list of functions that have been modified in git working tree
    
    .DESCRIPTION
        Uses git diff to identify functions that have been added or modified
        since the last commit, enabling new-code-only validation.
    
    .PARAMETER CompareWith
        Git reference to compare with (default: HEAD)
        
    .PARAMETER IncludeStaged
        Include staged changes in analysis
        
    .PARAMETER ModulePath
        Path to the module directory (default: auto-detected)
        
    .EXAMPLE
        Get-ChangedFunctions
        Gets functions modified in working directory since last commit
        
    .EXAMPLE
        Get-ChangedFunctions -CompareWith "main"
        Gets functions modified since main branch
        
    .EXAMPLE
        Get-ChangedFunctions -IncludeStaged
        Includes both staged and unstaged changes
    #>
    [CmdletBinding()]
    param(
        [string]$CompareWith = "HEAD",
        
        [switch]$IncludeStaged,
        
        [string]$ModulePath
    )
    
    Write-Host "Analyzing changed functions..." -ForegroundColor Cyan
    
    # Set default module path
    if (-not $ModulePath) {
        $ModulePath = Join-Path $script:ModulePath 'LoxoneUtils'
    }
    
    $changedFunctions = @()
    
    try {
        # Get git diff for PowerShell module files
        $diffArgs = @("diff")
        if ($IncludeStaged) {
            $diffArgs += "--cached"
        }
        $diffArgs += @("$CompareWith", "--name-only", "--", "$ModulePath/*.psm1")
        
        $changedFiles = & git @diffArgs 2>$null
        
        if (-not $changedFiles) {
            Write-Host "No changed PowerShell module files found" -ForegroundColor Gray
            return @()
        }
        
        Write-Host "Changed files: $($changedFiles.Count)" -ForegroundColor Yellow
        
        # For each changed file, get the detailed diff to identify changed functions
        foreach ($file in $changedFiles) {
            Write-Host "  Analyzing: $file" -ForegroundColor Gray
            
            # Get detailed diff for the file
            $detailDiffArgs = @("diff")
            if ($IncludeStaged) {
                $detailDiffArgs += "--cached"
            }
            $detailDiffArgs += @("$CompareWith", "--", $file)
            
            $diff = & git @detailDiffArgs 2>$null
            
            if ($diff) {
                # Parse diff to find function changes
                $functionPattern = '^\+.*function\s+([A-Z][\w-]+)'
                $modifiedFunctionPattern = '^\@@.*\+\d+,\d+.*\@@.*([A-Z][\w-]+)'
                
                foreach ($line in $diff) {
                    # New functions (lines starting with +)
                    if ($line -match $functionPattern) {
                        $funcName = $matches[1]
                        if ($funcName -notin $changedFunctions) {
                            $changedFunctions += $funcName
                            Write-Host "    Found new function: $funcName" -ForegroundColor Green
                        }
                    }
                    # Modified function contexts (hunk headers)
                    elseif ($line -match $modifiedFunctionPattern) {
                        $funcName = $matches[1]
                        if ($funcName -notin $changedFunctions) {
                            $changedFunctions += $funcName
                            Write-Host "    Found modified context: $funcName" -ForegroundColor Yellow
                        }
                    }
                }
            }
        }
        
        # Also check for completely new functions in working directory vs current coverage
        Write-Host "  Cross-checking with current function list..." -ForegroundColor Gray
        $currentCoverage = Get-TestCoverage -IncludeTestResults:$false
        
        # Get functions from the current files that might be new
        foreach ($file in $changedFiles) {
            if (Test-Path $file) {
                $content = Get-Content $file -Raw
                $functionMatches = [regex]::Matches($content, 'function\s+([A-Z][\w-]+)')
                
                foreach ($match in $functionMatches) {
                    $funcName = $match.Groups[1].Value
                    
                    # If function exists in current coverage but wasn't in git diff,
                    # it might be a newly added function
                    if ($funcName -notin $changedFunctions -and 
                        $currentCoverage.AllFunctions.ContainsKey($funcName)) {
                        
                        # Check if this might be a recent addition by checking git log
                        $logResult = & git log --oneline -1 --grep="$funcName" 2>$null
                        if ($logResult -or (& git log --oneline -5 --name-only | Select-String -Pattern $file)) {
                            $changedFunctions += $funcName
                            Write-Host "    Found potentially new function: $funcName" -ForegroundColor Cyan
                        }
                    }
                }
            }
        }
        
    } catch {
        Write-Warning "Git analysis failed: $($_.Exception.Message)"
        Write-Host "Falling back to manual change detection..." -ForegroundColor Yellow
        
        # Fallback: assume all untested functions are "changed"
        $coverage = Get-TestCoverage -IncludeTestResults:$false
        $changedFunctions = $coverage.AllFunctions.Keys | Where-Object {
            $func = $coverage.AllFunctions[$_]
            $func.Exported -and -not $func.Tested
        }
        
        Write-Host "Fallback detected $($changedFunctions.Count) untested functions as changed" -ForegroundColor Yellow
    }
    
    Write-Host "Total changed functions identified: $($changedFunctions.Count)" -ForegroundColor White
    
    return $changedFunctions
}


function Test-NewCodeCompliance {
    <#
    .SYNOPSIS
        Validates test coverage compliance only for new or modified code
    
    .DESCRIPTION
        Implements new-code-only validation by checking compliance only for
        functions that have been modified since a specified git reference.
        This allows gradual enforcement without breaking existing workflows.
    
    .PARAMETER CompareWith
        Git reference to compare with (default: HEAD)
        
    .PARAMETER IncludeStaged
        Include staged changes in analysis
        
    .PARAMETER StrictMode
        Fail if any new code violations are found
        
    .PARAMETER ShowViolations
        Display detailed violation information
        
    .PARAMETER ExceptionFile
        Path to exception file (default: TestCoverageExceptions.json)
        
    .EXAMPLE
        Test-NewCodeCompliance
        Validates compliance for functions modified since last commit
        
    .EXAMPLE
        Test-NewCodeCompliance -CompareWith "main" -StrictMode
        Strict validation against main branch (for CI)
        
    .EXAMPLE
        Test-NewCodeCompliance -ShowViolations
        Shows detailed information about any new violations
    #>
    [CmdletBinding()]
    param(
        [string]$CompareWith = "HEAD",
        
        [switch]$IncludeStaged,
        
        [switch]$StrictMode,
        
        [switch]$ShowViolations,
        
        [string]$ExceptionFile = "TestCoverageExceptions.json"
    )
    
    Write-Host "Testing New Code Compliance..." -ForegroundColor Cyan
    Write-Host "Comparing with: $CompareWith" -ForegroundColor Gray
    
    # Get list of changed functions
    $changedFunctions = Get-ChangedFunctions -CompareWith $CompareWith -IncludeStaged:$IncludeStaged
    
    if ($changedFunctions.Count -eq 0) {
        Write-Host "âœ… No function changes detected - compliance check passed" -ForegroundColor Green
        return @{
            Passed = $true
            ChangedFunctions = @()
            Violations = @()
            Message = "No changes detected"
        }
    }
    
    Write-Host "Validating $($changedFunctions.Count) changed functions..." -ForegroundColor Yellow
    
    # Run compliance check only on changed functions
    $complianceResult = Test-CoverageCompliance -ChangedFunctions $changedFunctions -ExceptionFile $ExceptionFile -ShowViolations:$ShowViolations
    
    # Analyze results for new code
    $newViolations = @()
    if ($complianceResult.Violations.Count -gt 0) {
        foreach ($violation in $complianceResult.Violations) {
            if ($violation.FunctionName -in $changedFunctions) {
                $newViolations += $violation
            }
        }
    }
    
    $passed = $newViolations.Count -eq 0
    
    # Report results
    Write-Host "`nNew Code Compliance Results:" -ForegroundColor White
    Write-Host "============================" -ForegroundColor White
    Write-Host "Changed functions analyzed: $($changedFunctions.Count)" -ForegroundColor Gray
    Write-Host "New violations found: $($newViolations.Count)" -ForegroundColor $(if ($newViolations.Count -eq 0) { "Green" } else { "Red" })
    
    if ($newViolations.Count -gt 0) {
        Write-Host "`nNew violations:" -ForegroundColor Red
        foreach ($violation in $newViolations) {
            Write-Host "  âŒ $($violation.FunctionName) ($($violation.Module))" -ForegroundColor Red
            if ($violation.Issues) {
                foreach ($issue in $violation.Issues) {
                    Write-Host "     - $issue" -ForegroundColor Yellow
                }
            }
        }
        
        Write-Host "`nðŸ’¡ Fix these violations by:" -ForegroundColor Cyan
        Write-Host "   1. Running: New-TestStub -FunctionName 'YourFunction'" -ForegroundColor Gray
        Write-Host "   2. Writing proper test cases" -ForegroundColor Gray
        Write-Host "   3. Adding exceptions to $ExceptionFile if justified" -ForegroundColor Gray
        
        if ($StrictMode) {
            throw "New code compliance failed: $($newViolations.Count) violations found"
        }
    } else {
        Write-Host "âœ… All new code complies with testing requirements!" -ForegroundColor Green
    }
    
    return @{
        Passed = $passed
        ChangedFunctions = $changedFunctions
        Violations = $newViolations
        TotalChecked = $changedFunctions.Count
        ComplianceRate = if ($changedFunctions.Count -gt 0) { 
            [math]::Round((($changedFunctions.Count - $newViolations.Count) / $changedFunctions.Count) * 100, 1) 
        } else { 100 }
        Message = if ($passed) { "All new code compliant" } else { "$($newViolations.Count) new violations found" }
    }
}


function Get-ComplianceViolations {
    <#
    .SYNOPSIS
        Gets a list of compliance violations for a specific module or all modules
    
    .DESCRIPTION
        Analyzes test coverage compliance and returns detailed violation information
        for troubleshooting and planning purposes.
    
    .PARAMETER ModuleName
        Specific module to analyze (analyzes all modules if not specified)
        
    .PARAMETER IncludeExempted
        Include functions that have exceptions in the results
        
    .EXAMPLE
        Get-ComplianceViolations
        Gets all compliance violations across all modules
        
    .EXAMPLE
        Get-ComplianceViolations -ModuleName "LoxoneUtils.TestTracking"
        Gets violations for a specific module
        
    .EXAMPLE
        Get-ComplianceViolations -IncludeExempted
        Includes exempted functions in the violation report
    #>
    [CmdletBinding()]
    param(
        [string]$ModuleName,
        
        [switch]$IncludeExempted
    )
    
    Write-Host "Analyzing compliance violations..." -ForegroundColor Cyan
    
    # Get coverage data
    $coverageData = Get-TestCoverage -IncludeTestResults:$false
    
    # Load exceptions
    $exceptions = @{ grandfathered = @{}; permanent = @{} }
    $exceptionPath = Join-Path (Split-Path $script:ModulePath -Parent) "TestCoverageExceptions.json"
    if (Test-Path $exceptionPath) {
        try {
            $exceptions = ConvertFrom-JsonToHashtable -Json (Get-Content $exceptionPath -Raw)
        } catch {
            Write-Warning "Could not load exception file: $exceptionPath"
        }
    }
    
    $violations = @()
    
    foreach ($funcName in $coverageData.AllFunctions.Keys) {
        $function = $coverageData.AllFunctions[$funcName]
        
        # Only check exported functions
        if (-not $function.Exported) { continue }
        
        # Filter by module if specified
        if ($ModuleName -and $function.Module -ne $ModuleName) { continue }
        
        # Check for violations
        $hasViolation = -not $function.Tested
        
        # Check exception status
        $hasException = $exceptions.grandfathered.ContainsKey($funcName) -or $exceptions.permanent.ContainsKey($funcName)
        
        # Include based on parameters
        if ($hasViolation -and (-not $hasException -or $IncludeExempted)) {
            $violations += [PSCustomObject]@{
                FunctionName = $funcName
                Module = $function.Module
                Tested = $function.Tested
                TestCount = $function.TestCount
                HasException = $hasException
                ExceptionType = if ($exceptions.grandfathered.ContainsKey($funcName)) { "Grandfathered" } 
                               elseif ($exceptions.permanent.ContainsKey($funcName)) { "Permanent" } 
                               else { "None" }
                ExceptionReason = if ($exceptions.grandfathered.ContainsKey($funcName)) { $exceptions.grandfathered[$funcName].reason }
                                 elseif ($exceptions.permanent.ContainsKey($funcName)) { $exceptions.permanent[$funcName].reason }
                                 else { "" }
                Priority = if ($function.Module -like "*TestTracking*") { "Low (Experimental)" }
                          elseif ($function.Module -like "*TestCoverage*") { "Low (Meta)" }
                          elseif ($function.Module -like "*Utility*") { "Medium" }
                          else { "High" }
            }
        }
    }
    
    # Sort by priority and module
    $violations = $violations | Sort-Object Priority, Module, FunctionName
    
    # Display summary
    Write-Host "`nCompliance Violations Summary:" -ForegroundColor Yellow
    Write-Host "=============================" -ForegroundColor Yellow
    Write-Host "Total violations: $($violations.Count)" -ForegroundColor White
    
    if ($violations.Count -gt 0) {
        $violationsByModule = $violations | Group-Object Module
        foreach ($group in $violationsByModule) {
            $exempted = ($group.Group | Where-Object HasException).Count
            $active = $group.Count - $exempted
            Write-Host "  $($group.Name): $($group.Count) total ($active active, $exempted exempted)" -ForegroundColor Gray
        }
        
        Write-Host "`nDetailed Violations:" -ForegroundColor White
        $violations | Format-Table FunctionName, Module, Priority, ExceptionType, ExceptionReason -AutoSize
    }
    
    return $violations
}


# Export module functions
Export-ModuleMember -Function @(
    'Get-TestCoverage',
    'New-TestCoverageReport',
    'Get-TestResults',
    'Test-CoverageCompliance',
    'Get-ComplianceViolations',
    'Get-ChangedFunctions',
    'Test-NewCodeCompliance'
)
